<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[web安全]]></title>
    <url>%2F2018%2F12%2F11%2Foauth%2F</url>
    <content type="text"><![CDATA[Web应用的安全管理，主要包括两个方面的内容：一方面是用户身份认证，即用户的登录设计；另一方面是用户的授权，即一个用户在一个应用系统中能够执行那些操作的权限管理。权限管理的设计一般使用角色来管理，即给一个用户赋予哪些角色，这个用户就具有哪些权限。]]></content>
      <categories>
        <category>web 安全 编程语言</category>
      </categories>
      <tags>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql]]></title>
    <url>%2F2018%2F12%2F06%2Fmysql%2F</url>
    <content type="text"><![CDATA[mysql体系结构和存储引擎 常用词定义 数据库（datebase）： 持久化的数据文件 实例(instance)：若干后台线程以及共享内存组成 mysql被设计成单进程多线程，通常一个数据库对应一个实例（集群是一个数据库多个实例），一般情况下，这两个概念不做区分 体系结构 这是一个插件式的体系结构，所以存储引擎是可定制的。 InnoDB存储引擎支持事务，设计目标是支持OLTP（面向在线事务处理）的应用，支持外键，读写锁，行锁等，高版本默认的存储引擎 MyISAM 存储引擎不支持事务，表锁设计，设计目标是支持OLAP(面向联机分析处理)的应用 逻辑结构 所有的数据逻辑地存放在一个表空间（tablespace） 表空间由段（segment）区（extent）页（page）组成 页是InnoDB最小的管理单位 InnoDB是索引组织表 InnoDB有聚集索引和辅助索引 事务四个特性（ACID） 原子性（Atomic）:对数据的操作，要么全执行，要么全不执行 一致性（Consistent）:事务在完成时，数据必须保持一致状态，数据结构必须是正确的（最难理解，可以想象分布式下数据不一致的状态） 隔离性（Isolation）:不用的事务修改不会影响彼此 持久性（Duration）:事务完成，影响必须是永久性的 隔离性一般通过锁实现，其他三个特性通过相关事务日志文件实现，Mysql redo log记录修改后的数据，undo log记录修改前数据 隔离级别 READ_UNCOMMITTED READ_COMMITTED REPEATABLE_READ SERIALIZABLE 从上到下，隔离性越高，并发性也就越差,死锁的记录也越大（gap间隙锁）设置这个级别是为了解决以下问题 参考Transaction 那点事儿 Dirty Read(脏读)：事务A读取了事务B修改未提交的数据（脏数据），并在此基础上进行了修改 Unrepeatable Read (不可重复读)：事务A读取了事务B已提交的更改数据 Phantom Read (幻读)：事务A读取了事务B已提交的新增数据 事务隔离级别 脏读 不可重复读 幻读 READ_UNCOMMITTED 允许 允许 允许 READ_COMMITTED 禁止 允许 允许 REPEATABLE_READ 禁止 禁止 允许 SERIALIZABLE 禁止 禁止 禁止 InnoDB锁类型 共享锁，读锁，其他事务可以继续加此锁 排它锁，写锁，排斥其他锁 意向锁，想要获得几行的锁 自增长锁 几种常见锁算法： 记录锁（Record-Lock）:锁着索引记录 间隙锁（gap）:锁住一段记录 next-key 锁，在PR隔离级别下是记录锁+间隙锁，InnoDB行的扫描锁定使用此算法 MVCC 多版本并发控制系统，在InnoDB中，在每行记录的后面增加两个隐藏列，记录创建版本号和删除版本号。 在 MVCC 中，对于读操作可以分为两种读： 快照读：读取的历史数据，简单的 select 语句，不加锁，MVCC 实现可重复读，使用的是 MVCC 机制读取 undo 中的已经提交的数据。所以它的读取是非阻塞的。 当前读：需要加锁的语句，update，insert，delete，select…for update 等等都是当前读。 这种机制用来防止幻读 spring事务传播机制 PROPAGATION_REQUIRED RROPAGATION_REQUIRES_NEW PROPAGATION_NESTED PROPAGATION_SUPPORTS PROPAGATION_NOT_SUPPORTED PROPAGATION_NEVER PROPAGATION_MANDATORY 理解：这种事务传播行为，定义了从方法A到方法B的传播行为，除此之外，涉及只读的操作建议加上(readonly=true)属性,提高读取性能 以下黄勇博客的解释： 方法 A 有事务吗？ 如果没有，就新建一个事务；如果有，就加入当前事务。这就是 PROPAGATION_REQUIRED，它也是 Spring 提供的默认事务传播行为，适合绝大多数情况。 如果没有，就新建一个事务；如果有，就将当前事务挂起。这就是 RROPAGATION_REQUIRES_NEW，意思就是创建了一个新事务，它和原来的事务没有任何关系了。 如果没有，就新建一个事务；如果有，就在当前事务中嵌套其他事务。这就是 PROPAGATION_NESTED，也就是传说中的“嵌套事务”了，所嵌套的子事务与主事务之间是有关联的（当主事务提交或回滚，子事务也会提交或回滚）。 如果没有，就以非事务方式执行；如果有，就使用当前事务。这就是 PROPAGATION_SUPPORTS，这种方式非常随意，没有就没有，有就有，有点无所谓的态度，反正我是支持你的。 如果没有，就以非事务方式执行；如果有，就将当前事务挂起。这就是 PROPAGATION_NOT_SUPPORTED，这种方式非常强硬，没有就没有，有我也不支持你，把你挂起来，不鸟你。 如果没有，就以非事务方式执行；如果有，就抛出异常。这就是 PROPAGATION_NEVER，这种方式更猛，没有就没有，有了反而报错，确实够牛的，它说：我从不支持事务！ 如果没有，就抛出异常；如果有，就使用当前事务。这就是 PROPAGATION_MANDATORY，这种方式可以说是牛逼中的牛逼了，没有事务直接就报错，确实够狠的，它说：我必须要有事务！]]></content>
      <categories>
        <category>数据库 编程语言</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oauth2]]></title>
    <url>%2F2018%2F11%2F29%2Foauth2%2F</url>
    <content type="text"><![CDATA[备注 /oauth/token 密码授权请求access_token /oauth/token_key 获取public_key 用于验证jwt的无篡改性 修改不支持swagger-ui ,暂时关闭csrf 1http.csrf().disable(); 解决Jhipster创建实体后，Gateway数据菜单为空 微服务创建完成后，打开网关服务，执行yo jhipster:entity NAME 选择Do you want to generate this entity from an existing microservice? Y]]></content>
  </entry>
  <entry>
    <title><![CDATA[activiti实战]]></title>
    <url>%2F2018%2F11%2F28%2Factiviti%2F</url>
    <content type="text"><![CDATA[activiti能干啥 1. activiti 是一种使用*.bpmn文件定义流程，管理流程的一种框架 1. 我们只需定义工作流，部署工作流就能执行工作流，实现工作流自动化 核心知识点 几大接口 1. RepositoryService，提供一系列管理流程部署和流程定义的API 1. RuntimeService，在流程运行时对流程实例进行管理与控制 1. TaskService，对流程任务进行管理，例如任务提醒、任务完成和创建任务等 1. HistoryService,对流程的历史数据进行操作，包括查询、删除这些历史数据 表结构 1. act_hi_ 历史数据表，hi是history的缩写，对应HistoryService接口 1. act_re_ 流程存储表，re是repository的缩写，对应RepositoryService接口，存储流程部署和流程定义等静态数据 1. act_ru_ 运行时数据表，ru是runtime的缩写，对应RuntimeService接口和TaskService接口，存储流程实例和用户任务等动态数据 代码实战 [github代码]() 1. spring-boot maven 支持 123456&lt;!-- https://mvnrepository.com/artifact/org.activiti/activiti-spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt; &lt;/dependency&gt; 2. 配置关键代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configurationpublic class ActivitiConfig &#123; @Bean public ProcessEngine processEngine(DataSourceTransactionManager transactionManager, DataSource dataSource) throws IOException &#123; SpringProcessEngineConfiguration configuration = new SpringProcessEngineConfiguration(); //自动部署已有的流程文件 Resource[] resources = new PathMatchingResourcePatternResolver().getResources(ResourceLoader.CLASSPATH_URL_PREFIX + &quot;processes/*.bpmn&quot;); configuration.setTransactionManager(transactionManager); configuration.setDataSource(dataSource); configuration.setDatabaseSchemaUpdate(&quot;true&quot;); configuration.setDeploymentResources(resources); configuration.setDbIdentityUsed(false); return configuration.buildProcessEngine(); &#125; @Bean public RepositoryService repositoryService(ProcessEngine processEngine) &#123; return processEngine.getRepositoryService(); &#125; @Bean public RuntimeService runtimeService(ProcessEngine processEngine) &#123; return processEngine.getRuntimeService(); &#125; @Bean public TaskService taskService(ProcessEngine processEngine) &#123; return processEngine.getTaskService(); &#125; @Bean public HistoryService historyService(ProcessEngine processEngine) &#123; return processEngine.getHistoryService(); &#125; @Bean public ManagementService managementService(ProcessEngine processEngine) &#123; return processEngine.getManagementService(); &#125; @Bean public IdentityService identityService(ProcessEngine processEngine) &#123; return processEngine.getIdentityService(); &#125;&#125; 3. 流程文件定义，路径resources/processes/*.bpmn 4. application.properties属性设置 1234#保存历史数据级别设置为full最高级别，便于历史数据的追溯spring.activiti.history-level=full# 自动部署验证设置:true-开启（默认）、false-关闭spring.activiti.check-process-definitions=true 5. 代码测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//发布流程@Testpublic void startFlow() &#123; Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;(); variables.put(&quot;applyId&quot;, 1); variables.put(&quot;masterId&quot;, 2); variables.put(&quot;archivorId&quot;, 3); variables.put(&quot;archiveMasterId&quot;, 4); variables.put(&quot;obligateId&quot;, 5); variables.put(&quot;next&quot;, true); //参数businessKey, variables为可选参数 ProcessInstance processInstance = runtimeService.startProcessInstanceByKey(&quot;integral&quot;, variables); System.out.println(&quot;id:&quot; + processInstance.getId() + &quot;,activitiId:&quot; + processInstance.getActivityId());//22501 Task task1 = taskService.createTaskQuery().taskAssignee(String.valueOf(1)).list().get(0); Map&lt;String, Object&gt; variables1 = new HashMap&lt;&gt;(); variables1.put(&quot;pass1&quot;, true); variables1.put(&quot;type&quot;, 1); taskService.setVariableLocal(task1.getId(), &quot;applyId&quot;, 1); taskService.complete(task1.getId(), variables1); //部长 Task task2 = taskService.createTaskQuery().taskAssignee(String.valueOf(2)).list().get(0); taskService.setAssignee(task2.getId(), String.valueOf(6)); Task task21 = taskService.createTaskQuery().taskAssignee(String.valueOf(6)).list().get(0); Map&lt;String, Object&gt; variables2 = new HashMap&lt;&gt;(); variables2.put(&quot;pass2&quot;, true); taskService.complete(task21.getId(), variables2); //归口 Task task3 = taskService.createTaskQuery().taskAssignee(String.valueOf(3)).list().get(0); Map&lt;String, Object&gt; variables3 = new HashMap&lt;&gt;(); variables3.put(&quot;pass3&quot;, true); taskService.complete(task3.getId(), variables3); //归口部长 Task task4 = taskService.createTaskQuery().taskAssignee(String.valueOf(4)).list().get(0); Map&lt;String, Object&gt; variables4 = new HashMap&lt;&gt;(); variables4.put(&quot;pass4&quot;, true); variables4.put(&quot;price&quot;, 10); taskService.complete(task4.getId(), variables4); // Task task5 = taskService.createTaskQuery().taskAssignee(String.valueOf(5)).list().get(0); Map&lt;String, Object&gt; variables5 = new HashMap&lt;&gt;(); variables5.put(&quot;pass6&quot;, true); taskService.complete(task5.getId(), variables5); historyTaskList(processInstance.getId());&#125; 6. 监听类设置 12345678910public class ObligateAuditListener implements TaskListener &#123;@Overridepublic void notify(DelegateTask delegateTask) &#123; if (delegateTask.getEventName().equals(&quot;create&quot;)) &#123; &#125; if (delegateTask.getEventName().equals(&quot;complete&quot;)) &#123; &#125;&#125; 参考 官网 Activiti6简明教程 详细文档]]></content>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java类加载]]></title>
    <url>%2F2018%2F09%2F17%2Floading%2F</url>
    <content type="text"><![CDATA[类加载过程 1. 加载（loading） 2. 链接（linking） 2.1. 验证（Verification） 2.2. 准备（Preparation） 2.3 解析（Resolution） 3. 初始化（initialization） 双亲委派 - 目的 ：避免重复加载java类型 java 8 以前的类加载器 1.启动类加载器（BootStrap Class-Loader）,加载jre/lib,如rt.jar 2.扩展类加载器（Extension or Ext Class-Loader）/jre/lib/ext（java9重命名为平台类加载器Platform Class-Loader） 3.应用类加载器（Application or App Class-Loader） 自定义类加载过程 1. 通过指定名称，并加载二进制 2. 创建class对象，二进制到class的转化 备注 - 当一个类或一个资源文件存在多个jar中，就会出现jar hell问题，解决办法就是自己加载手动通过cassloader加载类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java集合]]></title>
    <url>%2F2018%2F09%2F06%2Fjava-collection%2F</url>
    <content type="text"><![CDATA[ArrayList:数组实现，适合随机访问，插入和删除除了尾部外性能较差 LinkList: 链表实现，插入删除高效，随机访问差 Queue/Deque: java 标准队列实现 TreeSet: 利用TreeMap实现，value为Dummy对象&quot;PRESENT&quot;,其插入元素以键的形式放入TreeMap里面 同步时可用Collections包装 static List synchronize... Collections.sort(),底层调用Arrays.sort(),对于 小数据集，采用二分插入 原始数据类型，采用双轴快速排序 对象数据类型，采用TimSort,优化过的归并和二分插入排序 HashMap: put,get操作可以达到常数时间的性能，所以是绝大多数利用键值存取场景的首选 TreeMap: 基于红黑树的一种顺序访问的Map,get,put,remove操作是O(log(n)) 基本约定: equals 相等，hashCode 一定要相等。 重写了hashCode 也要重写equals LinkedHashMap顺序存储，例如重写removeEldestEntry可以实现定量过期删除 负载因子*容量&gt;元素数量,同时元素数量应该是2的幂（确保hash 均匀），倍数扩容 ConcurrentHashMap二级hash,进行分段加锁保证性能 31*N可以被编译器优化为左移5位后减1，有较高的性能]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle笔记]]></title>
    <url>%2F2018%2F07%2F19%2Foracle%2F</url>
    <content type="text"><![CDATA[实用sql 123456789101112131415161718192021222324252627282930313233343536373839404142/* --输出表中行 */declarecl_loan_row cl_loan%rowtype; begin select * into cl_loan_row from cl_loan where loan_key= '31' and fdate = '20121103';dbms_output.put_line(cl_loan_row.loan_no);end;//* ----复制表的结构 */create table cl_loan_bak as select * from cl_loan where rownum &lt; 1select replace(fdate,'20121103','20121102') from cl_loan where fdate = '20121103';/*四舍五入 */select round(23.45434,2),round(23.355,2) from dual;集合运算intersectunion allunionminus--动态sql的语法execute immediate sqlstr[into 变量列表】【using 参数列表]建表str_sql := 'create table '||table_name||'('||c1||' '||datatype||')';execute immediate str_sql;str_sql := 'insert into table_name valus(:1,:2)';execute immediate str_sql using (1,'hello');查找列存在重复值得记录SELECT * FROM TP_IND_CR_01_01_MID WHERE col_0 IN ( SELECT col_0 FROM TP_IND_CR_01_01_MID GROUP BY col_0 HAVING COUNT ( * ) &gt;= 2)--/ 告诉数据库可以执行语句（脚本文件中不要用；代替/)--truncate table table_name 游标 12345678910111213141516171819202122232425262728293031/* Formatted on 2015-11-8 19:21:12 (QP5 v5.114.809.3010) */declarec_no stu.sno%type;c_name stu.stu.name%type;cursor cur_stuisselect * from stu;beginopen cur_stu;loop fetch cur_stu into c_no,c_name; exit when cur_stu%notfound; c_sum := cur_stu%rowcount; dbms_output.put_line('学生的学号'||c_no||'姓名'||c_name); end loop; close cur_stu;end;/--fordeclarestu_row stu%rowtype;cursor cur_stuisselect * from stu;beginfor stu_row in cur_stuloop dbms_output.put_line('学生的学号'||stu_row.c_no||'姓名'||stu_row.c_name); end loop;end;/ 触发器的使用 123456789101112131415create or replace trigger tri_yjbefore[after][instead] insert or update or delete on stubegainif updating or inserting or daleting thendbms_output_line('触发语句触发器');end if;end;create or replace trigger tri_yjbefore[after][instead] insert or update or delete on stufor each rowbegainif updating or inserting or daleting thendbms_output_line('行触发器');end if;end; 自定义异常 12345678910111213declare myexp exception;beginif sum=0 thenraise myexp;end if;exception when no_data_found thenDBMS_OUTPUT.PUT_LINE('无数据');when myexp then DBMS_OUTPUT.PUT_LINE('自定义异常');when others thenend;/]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO]]></title>
    <url>%2F2018%2F07%2F05%2Fnio%2F</url>
    <content type="text"><![CDATA[I/O模型 阻塞与非阻塞：阻塞调用是指调用结果返回之前，当前线程被挂起。调用线程只有在得到结果之后才会继续。非阻塞是指调用方在未得到被调用方的结果，并不会发生阻塞。 异步同步：同步处理是指被调用方得到最终结果之后才返回给调用方；异步处理是指被调用方先返回应答，然后再计算调用结果，计算完最终结果后再通知并返回给调用方。 5 种IO模型 1. 阻塞式I/O 模型（blocking i/o） 2. 非阻塞I/O 模型（non-blocking i/o） 3. I/O 复用 （I/O multiplexing） 4. 信号驱动式I/O 模型（signal-dirven I/O) 5. 异步I/O 模型（asynchronous I/O） 线程模型 1.传统阻塞I/O服务模型 2.针对1改进方案a:基于I/O复用模型 3.针对1改进方案b:基于线程池复用线程资源 4.结合2和3的Reactor（Dispatch）模型 5.常见模型主从reactor+多线程池（Nginx） 6.异步Proactor模型 Java NIO和IO的主要区别 IO NIO 面向流 面向缓冲 阻塞IO 非阻塞IO 无 选择器 BIO 常见类图 Buffer的基本用法 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法（compact()方法只会清除已经读过的数据，clear()方法会清空整个缓冲区） 12345678910111213141516171819202122public class FileChannelDemo &#123; public static void main(String[] args) &#123; try (RandomAccessFile rw = new RandomAccessFile("c:/test/test.txt", "rw")) &#123; FileChannel channel = rw.getChannel(); ByteBuffer byteBuffer = ByteBuffer.allocate(2); int read = channel.read(byteBuffer); while (read!=-1)&#123; System.out.println(read); byteBuffer.flip(); while (byteBuffer.hasRemaining())&#123; System.out.println((char) byteBuffer.get()); &#125; byteBuffer.clear(); read=channel.read(byteBuffer); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Buffer的capacity,position和limit 三种实现方式 HeapByteBuffer DirectByteBuffer MappedByteBuffer FileChannel transferFrom() transferTo() 123456789101112try (RandomAccessFile rw = new RandomAccessFile("c:/test/test.txt", "rw"); RandomAccessFile rw1 = new RandomAccessFile("c:test/test1.txt", "rw")) &#123; FileChannel from = rw.getChannel(); FileChannel to = rw1.getChannel(); long position = 0; long count = from.size(); from.transferTo(position, count, to); to.transferFrom(from,position, count); &#125; 强制写进磁盘 channel.force(true); SocketChannel 打开一个SocketChannel并连接到互联网上的某台服务器 一个新连接到达ServerSocketChannel时，会创建一个SocketChannel Selector 创建 1Selector selector = Selector.open(); 注册 123channel.configureBlocking(false); SelectionKey key = channel.register(selector,Selectionkey.OP_READ); 监听事件 Connect(SelectionKey.OP_CONNECT) Accept(SelectionKey.OP_ACCEPT) Read(SelectionKey.OP_READ) Write(SelectionKey.OP_WRITE) SelectionKey 123456789101112131415161718192021222324Selector selector = Selector.open(); channel.configureBlocking(false); SelectionKey key =channel.register(selector,SelectionKey.OP_READ); while (true)&#123; int ready = selector.select(); if (ready==0) continue; //一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext())&#123; SelectionKey key1 = iterator.next(); if (key.isAcceptable())&#123; &#125;else if (key.isConnectable())&#123; &#125;else if (key.isReadable())&#123; &#125;else if (key.isWritable())&#123; &#125; //。必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。 iterator.remove(); &#125; &#125; AsynchronousFileChannel 1234567891011121314151617181920212223242526272829public static void main(String[] args) throws InterruptedException &#123; Path path = Paths.get("c:", "/test/test.txt"); try &#123; AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ); ByteBuffer buffer=ByteBuffer.allocate(100); // ByteBuffer buffer2=ByteBuffer.allocate(2); long position=0; fileChannel.read(buffer, position, buffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; System.out.println("result:"+result); attachment.flip(); byte[] data=new byte[attachment.limit()]; attachment.get(data); System.out.println("sdf"+new String(data)); attachment.clear(); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; &#125; &#125;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; Thread.sleep(100); &#125; ## 参考 I/O网络模型 I/O api java NIO tutorials 有人要将“高并发”拉下“神坛”!]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>java 编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jhipster初探]]></title>
    <url>%2F2018%2F07%2F03%2Fjhipster%2F</url>
    <content type="text"><![CDATA[安装 本地生成 官网介绍 先决：安装 Java， Git， Node.js， Yarn和 Yeoman 安装JHipster yarn global add generator-jhipster 创建一个新目录并进入它 mkdir myApp &amp;&amp; cd myApp 运行JHipster并按照屏幕上的说明操作 jhipster 具体参数见下图（生成单体应用）： 生成spring boot + augular5的单体架构应用 等下载完成后输入mvnw(linux下为./mvnw)即可在8080提供服务 自带一些监控运维相关应用 下载jdl-studio 生成代码jhipster import-jdl ./my-jdl-file.jdl --json-only 在线生成 在线生成的好处就是不需要本次安装那么多软件 地址 微服务 Consul 服务发现与注册 jhipster 微服务注册与发现可以采用consul,网关代理可以采用Traefik jhipster 服务发现与注册 1. 创建顺序 1. JHipster UAA server 1. 一个微服务 1. 一个 JHipster 网关 1. `./mvnw verify -Pprod dockerfile:build dockerfile:tag@version dockerfile:tag@commit`生成各个服务的docker镜像 1. 生成docker-compose管理各个服务 ####备注 123456dto A, B with mapstructpaginate A, C with infinite-scrollpaginate Job with paginationpaginate B with pagerservice A with serviceClassservice C with serviceImpl]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>编程语言 jhipster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk常用工具类]]></title>
    <url>%2F2018%2F07%2F02%2Futil%2F</url>
    <content type="text"><![CDATA[Java里面给一个类的操作工具惯用的设计是给这个类后缀加s(Object-&gt;Objects,Array-&gt;Arrays,collection-&gt;collections) Objects 1234567891011121314151617181920212223242526//比较两个对象是否相等（首先比较内存地址，然后比较a.equals(b)，只要符合其中之一返回true）public static boolean equals(Object a, Object b);//深度比较两个对象是否相等(首先比较内存地址,相同返回true;如果传入的是数组，则比较数组内的对应下标值是否相同)public static boolean deepEquals(Object a, Object b);//返回对象的hashCode，若传入的为null，返回0public static int hashCode(Object o);//返回传入可变参数的所有值的hashCode的总和（这里说总和有点牵强，具体参考Arrays.hashCode()方法）public static int hash(Object... values);//返回对象的String表示，若传入null，返回null字符串public static String toString(Object o)//返回对象的String表示，若传入null，返回默认值nullDefaultpublic static String toString(Object o, String nullDefault)//使用指定的比较器c 比较参数a和参数b的大小（相等返回0，a大于b返回整数，a小于b返回负数）public static &lt;T&gt; int compare(T a, T b, Comparator&lt;? super T&gt; c) //如果传入的obj为null抛出NullPointerException,否者返回objpublic static &lt;T&gt; T requireNonNull(T obj) //如果传入的obj为null抛出NullPointerException并可以指定错误信息message,否者返回objpublic static &lt;T&gt; T requireNonNull(T obj, String message) Arrays List转换成为数组 1String[] arr = (String[])list.toArray(new String[size]); 数组转换成为List 12String[] arr = new String[] &#123;"1", "2"&#125;;List list = Arrays.asList(arr); 数组的复制 1234567java.lang.System public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length) 还有常用的copyof(array,length)：把数组array复制成一个长度为length的新数组 Files &amp;&amp; Paths Paths.get() Path.normallize() Files.exists() Files.createDirectory() Files.copy() Files.move() Files.delete() Files.walkFileTree()]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>java 编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java积极使用optional替代null]]></title>
    <url>%2F2018%2F07%2F02%2Foption%2F</url>
    <content type="text"><![CDATA[Java中有值类型和引用类型，null是引用类型的默认值，是对于不确定指针的建模，正常情况下，堆中的对象解引用调用，当声明的变量不指向任何堆中的对象时，此时调用任何方法都将引发过NullPointerException，因此在Java对象调用时，理论上必须要判断此对象为空（12345678910111213141516171819### Optional的方法 |方法|描述||-|-||empty |返回一个空的 Optional 实例||filter|如果值存在并且满足提供的词，就返回包含该值的 Optional 对象；否则返回一个空的 Optional 对象||flatMap| 如果值存在，就对该值执行提供的 mapping函数调用，返回一个 Optional 类型的值，否则就返 回一个空的Optional 对象 |get| 如果该值存在，将该值用 Optional 封装返回，否则出一个 NoSuchElementException 异常 ||ifPresent| 如果值存在，就执行使用该值的方法调用，否则什么也不做| |isPresent| 如果值存在就返回 true，否则返回 false ||map |如果值存在，就对该值执行提供的 mapping函数调用| |of| 将指定值用 Optional 封装之后返回，如果该值为 null，则出一个 NullPointerException 异常 |ofNullable| 将指定值用 Optional 封装之后返回，如果该值为 null，则返回一个空的 Optional 对象 |orElse| 如果有值则将其返回，否则返回一个认值 orElseGet 如果有值则将其返回，否则返回一个由指定的 Supplier 接口生成的值 |orElseThrow| 如果有值则将其返回，否则出一个由指定的 Supplier 接口生成的异常### 创建optional对象1. 创建空Optional ```java Optional&lt;Object&gt; empty = Optional.empty(); 据一个空值创建Optional 1Optional&lt;Car&gt; optCar = Optional.of(car); 可接null的Optional 1Optional&lt;Person&gt; optperson = Optional.ofNullable(person); 实践 使用Optional定义数据模型 1234567891011121314151617 public class Person &#123; private Optional&lt;Car&gt; car; public Optional&lt;Car&gt; getCar() &#123; return car; &#125; &#125; ``` - 注意，上述字段并不能序列化，对于要序列化的数据模型，可改写成如下 ```java class Person &#123; private Car car; public Optional&lt;Car&gt; getCarAsOptional() &#123; return Optional.ofNullable(car); &#125; &#125; 重构以下常见代码 123456public String getName(Person p)&#123; if (p!=null)&#123; return p.gerName(); &#125; return null; &#125; 12345public String getNameOpt(Person p)&#123; return Optional.ofNullable(p) .map(v-&gt;v.gerName()) .orElse(""); &#125; 使用option重构后的代码可以进行链式调用了，相当简洁，查看Java8新增的流api,比如map,fiter其返回值都是optional这种null类型安全的 总结 null引用在历上被引入到程序设计语言中，目的是为了表示变量值的缺失。 Java 8中引入了一个新的类java.util.Optional，对存在或缺失的变量值进行 建模。 你可以使用静态工厂方法Optional.empty、Optional.of以及Optional.ofNull- able创建Optional对象。 Optional类支持多种方法，比如map、flatMap、filter，它们在概念上与Stream类 中对应的方法分相似。 使用Optional会使你更积极地解引用Optional对象，以应对变量值缺失的问题， 最终，你能更有效地防止代码中出现不期而至的空指针异常。 使用Optional能帮助你设计更好的API，用户只需要读方法签名，就能了解该方法是 否接受一个Optional类型的值。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>java 编程语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入并发]]></title>
    <url>%2F2018%2F05%2F29%2Fmemory%2F</url>
    <content type="text"><![CDATA[并发编程模型的分类 执行体：可以是线程也可以是协程，执行代码的承载体 1. 共享内存：执行体之间通过写-读内存中的公共状态来隐式进行通信 1. 消息传递：执行体间必须通过明确的发送消息来显式进行通信 顺序一致性内存模型是一个理论参考模型 ,处理器内存模型是硬件级的内存模型，JMM是一个语言级的内存模型 顺序一致性内存模型 1. 一个线程中的所有操作必须按照程序的顺序来执行 1. （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序 在顺序一致性模型中，所有操作完全按程序的顺序串行执行 处理器内存模型 涉及术语：Socket|Processor，core，HT超线程，DRAM,SRAM对应上图对号入座 MESI协议：解决内存可见性 重排序 在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度 1. 编译器优化 1. 指令级并行 1. 内存重排序(现代的处理器都会允许对写-读操作重排序) 对于1，JMM的编译器重排序规则会禁止特定类型的编译器重排序,对于2,3属于处理器重排序，JMM通过内存屏障指令来禁止特定类型的处理器重排。对于3，`a=1;b=2`如果处理器先执行`a=1`,写入缓存，再读取b，再将a=1刷入内存，从内存角度看，先读取b,然后设置的a=1 内存屏障 处理器使用写缓冲区通过批处理的方式刷新写缓冲区，允许对写-读操作重排序，但仅对当前处理器可见，会影响其他处理器对内存的操作，因此需要有种指令阻止这种重排序，有四种LoadLoad ，StoreStore ，LoadStore ，StoreLoad ，例如StoreLoad 意味着store happen before load 根据对不同类型读/写操作组合的执行顺序的放松,分以下几种类型： 1. TSO：放松程序中写-读操作的顺序 2. PSO：在前面1的基础上，继续放松程序中写-写操作的顺序 3. RMO和PowerPC：在前面1和2的基础上，继续放松程序中读-写和读-读操作的顺序 如何实现原子性 在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和I/O设备执行内存的读/写。总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行；在任意时间点，最多只能有一个处理器能访问内存。这个特性确保了单个总线事务之中的内存读/写操作具有原子性 cache 伪共享 由于CPU加载数据最小单位cacheLine，所以写同一个line的不同属性会发生cachemiss，jdk8采用@Contended 12345@Contendedpublic class App &#123; public int a; public int b;&#125; java内存模型 Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见（记住，这是语言层面的内存抽象模型） 从整体来看，是线程通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供以下内存可见性保证 1. 单线程程序，JMM保证执行结果与该程序在顺序一致性模型中的执行结果相同 2. 正确同步的多线程程序，JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证 happens-before 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作 传递性：如果A happens- before B，且B happens- before C，那么A happens- before C volatile变量规则：对一个volatile域的写，happens- before 于任意后续对这个volatile域的读 123456789101112131415class Example &#123;int a = 0;volatile boolean flag = false;public void writer() &#123; a = 1; // 1 flag = true; // 2&#125;public void reader() &#123; if (flag) &#123; //3 int i = a; //4 &#125;&#125;&#125; 假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens before规则，这个过程建立的happens before 关系可以分为两类 1. 根据程序次序规则，1 happens before 2; 3 happens before 4。 2. 根据volatile规则，2 happens before 3。 3. 根据happens before 的传递性规则，1 happens before 4。 volatile写的内存语义 - 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存 - 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁 123456789101112class Example &#123; int a = 0; public synchronized void writer() &#123; // 1 a++; // 2 &#125; // 3 public synchronized void reader() &#123; // 4 int i = a; // 5 &#125;&#125; 假设线程A执行writer()方法，随后线程B执行reader()方法。根据happens before规则，这个过程包含的happens before 关系可以分为两类： 根据程序次序规则，1 happens before 2, 2 happens before 3; 4 happens before 5, 5 happens before 6。 根据监视器锁规则，3 happens before 4。 根据happens before 的传递性，2 happens before 5。 锁释放和获取的内存语义 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中 当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须要从主内存中去读取共享变量 注：happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，并不意味着前一个操作必须要在后一个操作之前执行，比如单线程中a=3;b=4;b的赋值可能先于a的赋值发生 concurrent包的源代码实现，会发现一个通用化的实现模式 首先，声明共享变量为volatile； 然后，使用CAS的原子条件更新来实现线程之间的同步； 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。 123456789101112131415//在ReentrantLock中，调用lock()方法获取锁；调用unlock()方法释放锁class Example &#123; private AtomicReference&lt;Thread&gt; sign = new AtomicReference&lt;&gt;(); public void lock() &#123; Thread current = Thread.currentThread(); while (!sign.compareAndSet(null, current)) &#123; &#125; &#125; public void unlock() &#123; Thread current = Thread.currentThread(); sign.compareAndSet(current, null); &#125;&#125; as-if-serial 不管怎么重排序，（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守as-if-serial语义，如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。单个处理器中执行的指令序列和单个线程中执行的操作不会改变这种数据依赖性，多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果，因此顺序性保证交由程序员 常见java通信方式 A线程写volatile变量，随后B线程读这个volatile变量。 A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键 总结 线程中的每个操作happens before该线程中在程序顺序上后续的每个操作。 解锁一个监视器的操作happens before随后对相同监视器进行锁的操作。 对volatile字段的写操作happens before后续对相同volatile字段的读取操作。 线程上调用start()方法happens before这个线程启动后的任何操作。 一个线程中所有的操作都happens before从这个线程join()方法成功返回的任何其他线程。（注意思是其他线程等待一个线程的jion()方法完成，那么，这个线程中的所有操作happens before其他线程中的所有操作） go内存模型 执行体为Goroutine,内存模型的目的是定义变量的读写在执行体中的可见性，编译期重排和CPU指令重排导致代码执行逻辑和书写逻辑不一致，go内存模型基于CSP，goroutine通过channel通信 Happens Before Happens-before用来指明Go程序里的内存操作的局部顺序。如果一个内存操作事件e1 happens-before e2，则e2 happens-after e1也成立；如果e1不是happens-before e2,也不是happens-after e2，则e1和e2是并发的。 从本质上来讲，happens-before规则确定了CPU缓冲和主存的同步时间点（通过内存屏障等指令），从而使得对变量的读写顺序可被确定–也就是我们通常说的“同步”。 单独的goroutine里面，虽然有重排，但是最终结果和代码顺序执行结果一致 12345678var a, b, c intfunc main() &#123; a = 1 b = 2 c = a + 2 log.Println(a, b, c)&#125; a=1和b=2执行顺序不保证，但是c=a+2 happen before a=1 在多个Goroutine里如果要访问一个共享变量，我们就必须使用同步工具来建立happens-before条件，来保证对该变量的读操作能读到期望的修改值。 以下是具体的可被利用的Go语言的happens-before规则 如果package p 引用了package q，q的init()方法 happens-before p main.main()方法 happens-after所有package的init()方法结束 go语句创建新的goroutine happens-before 该goroutine执行 Goroutine的退出并不保证happens-before任何事件 对一个缓冲Channel的发送操作(send) happens-before 相应Channel的接收操作完成 关闭一个Channel happens-before 从该Channel接收到最后的返回值0 12345678910111213141516//a = "hello, world" happens-before c &lt;- 0，print(a) happens-after &lt;-c， 根据上面的规则1）以及happens-before的可传递性，a = "hello, world" happens-beforeprint(a)var c = make(chan int, 10)var a stringfunc f() &#123; a = "hello, world" //c &lt;- 0 close(c) //关闭操作在&lt;-c接收到0之前发送 &#125;func main() &#123; go f() &lt;-c print(a)&#125; 不带缓冲的Channel的接收操作（receive） happens-before 相应Channel的发送操作完成 12345678910111213//c是不带缓冲的Channel，a = "hello, world" happens-before &lt;-c happens-beforec &lt;- 0 happens-before print(a)， 但如果c是缓冲队列，如定义c = make(chan int, 1), 那结果就不确定了var c = make(chan int)var a stringfunc f() &#123; a = "hello, world" &lt;-c&#125;func main() &#123; go f() c &lt;- 0 print(a)&#125; 任何sync.Mutex或sync.RWMutex 变量（l），定义 n &lt; m， 第n次 l.Unlock() happens-before 第m次l.lock()调用返回 1234567891011121314 //a = "hello, world" happens-before l.Unlock() happens-before 第二个 l.Lock() happens-beforeprint(a) var l sync.Mutex var a string func f() &#123; a = "hello, world" l.Unlock() &#125; func main() &#123; l.Lock() go f() l.Lock() print(a)&#125; once.Do(f)中的f() happens-before 任何多个once.Do(f)调用的返回，且f()有且只有一次调用 12345678910111213141516//调用两次doprint()，但实际上setup只会执行一次，并且并发的once.Do(setup)都会等待setup返回后再继续执行var a stringvar once sync.Oncefunc setup() &#123; a = "hello, world" fmt.Println(1)&#125;func doprint() &#123; once.Do(setup) fmt.Println(2)&#125;func main() &#123; go doprint() go doprint() time.Sleep(time.Second)&#125; 错误的同步 感受下以下代码的捉摸不定 1234567891011121314151617var a, b int//输出四种可能的结果func f() &#123; a = 1 b = 2&#125;func g() &#123; print(b) print(a)&#125;func main() &#123; go f() g()&#125; 目的是告诉我们一定要显式地使用同步 参考 并发编程网 Go的内存模型]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>java内存模型 golang内存模型 并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习与深度学习]]></title>
    <url>%2F2018%2F05%2F17%2FML-DL%2F</url>
    <content type="text"></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于keras认识深度学习]]></title>
    <url>%2F2018%2F05%2F17%2Fai_notebook%2F</url>
    <content type="text"><![CDATA[为什么选择 编程友好：在学习深度学习原理过程中，最好自己代码实践，keras极度适合初学者，能快速实验 安装 Anaconda 和 Jupyter notebook已成为数据分析的标准环境 anaconda安装 jupyter notebook安装 keras安装 ps:直接导入环境配置文件，命令conda env update -f=keras_environment.yml 定义模型 Sequential()模型 123model = Sequential()model.add(Dense(32, input_shape=(784,)))model.add(Activation(&apos;relu&apos;)) Functional()模型 123a = Input(shape=(32,))b = Dense(32)(a)model = Model(inputs=a, outputs=b) 编译模型 1model.compile(optimizer=&apos;sgd&apos;, loss=&apos;mse&apos;) 必须传入损失函数和优化算法 训练模型 1history = model.fit(X, y, batch_size=10, epochs=100) 使用反向传播算法对数据进行训练 评估模型 1loss, accuracy = model.evaluate(X, y) 模型预测 1predictions = model.predict(x) 线性回归 Keras对波士顿房价进行回归 定义模型假设为y=Wx+b 编译模型时选择损失函数为均方误差函数，优化算法选择随机梯度下降 传入数据以及迭代此时 均方误差函数进行评估 进行预测 12345678910111213141516171819202122from keras.datasets import boston_housingfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.optimizers import SGDimport matplotlib.pyplot as pltimport numpy as np# Boston房屋价格回归数据集# 每条数据含有13个属性，目标值是该位置房子的房价中位数(x_train, y_train), (x_test, y_test) = boston_housing.load_data()# 构建模型# Dense就是常用的全连接层，所实现的运算是output = activation(dot(input, kernel)+bias)model = Sequential()model.add(Dense(1,input_dim=13))# 编译model.compile(optimizer=SGD(lr=0.01,clipnorm=1),loss='mse',metrics=['mse'])# 训练cost = model.fit(x_train,y_train,epochs=20)# 评估score = model.evaluate(x_test,y_test)#预测y_pred = model.predict(x_test[0:1,:])print(y_pred) Epoch 1/20 404/404 [==============================] - 0s 527us/step - loss: 13144.4827 - mean_squared_error: 13144.4827 Epoch 2/20 404/404 [==============================] - 0s 40us/step - loss: 3041.2153 - mean_squared_error: 3041.2153 Epoch 3/20 404/404 [==============================] - 0s 45us/step - loss: 668.1933 - mean_squared_error: 668.1933 Epoch 4/20 404/404 [==============================] - 0s 42us/step - loss: 255.8141 - mean_squared_error: 255.8141 Epoch 5/20 404/404 [==============================] - 0s 40us/step - loss: 185.1011 - mean_squared_error: 185.1011 Epoch 6/20 404/404 [==============================] - 0s 40us/step - loss: 170.2183 - mean_squared_error: 170.2183 Epoch 7/20 404/404 [==============================] - 0s 40us/step - loss: 165.1749 - mean_squared_error: 165.1749 Epoch 8/20 404/404 [==============================] - 0s 37us/step - loss: 161.2603 - mean_squared_error: 161.2603 Epoch 9/20 404/404 [==============================] - 0s 35us/step - loss: 151.0976 - mean_squared_error: 151.0976 Epoch 10/20 404/404 [==============================] - 0s 35us/step - loss: 147.1785 - mean_squared_error: 147.1785 Epoch 11/20 404/404 [==============================] - 0s 40us/step - loss: 140.4976 - mean_squared_error: 140.4976 Epoch 12/20 404/404 [==============================] - 0s 42us/step - loss: 140.6603 - mean_squared_error: 140.6603 Epoch 13/20 404/404 [==============================] - 0s 40us/step - loss: 132.6787 - mean_squared_error: 132.6787 Epoch 14/20 404/404 [==============================] - 0s 40us/step - loss: 128.5385 - mean_squared_error: 128.5385 Epoch 15/20 404/404 [==============================] - 0s 37us/step - loss: 123.0882 - mean_squared_error: 123.0882 Epoch 16/20 404/404 [==============================] - 0s 40us/step - loss: 118.4096 - mean_squared_error: 118.4096 Epoch 17/20 404/404 [==============================] - 0s 40us/step - loss: 123.5432 - mean_squared_error: 123.5432 Epoch 18/20 404/404 [==============================] - 0s 42us/step - loss: 115.5308 - mean_squared_error: 115.5308 Epoch 19/20 404/404 [==============================] - 0s 40us/step - loss: 112.0784 - mean_squared_error: 112.0784 Epoch 20/20 404/404 [==============================] - 0s 37us/step - loss: 114.4626 - mean_squared_error: 114.4626 102/102 [==============================] - 0s 324us/step [[15.296406]] 查看模型 1234from IPython.display import SVGfrom keras.utils.vis_utils import model_to_dotSVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg')) 12345678910111213141516171819202122232425### 单变量线性回归# 构造数据x=np.linspace(-10,10,100)np.random.shuffle(x)y=5*x+10+np.random.normal(0,5,(100,))#加入噪声x_train,y_train,x_test,y_test = x[:80],y[:80],x[80:],y[80:]#训练数据与测试数据8：2# 构建模型# Dense就是常用的全连接层，所实现的运算是output = activation(dot(input, kernel)+bias)model = Sequential()model.add(Dense(1,input_dim=1))# 编译model.compile(optimizer='sgd',loss='mse',metrics=['mse'])# 训练cost = model.fit(x_train,y_train,epochs=20,verbose=0)# 评估score = model.evaluate(x_test,y_test)#预测y_pred = model.predict(x_test)# 可视化y_pred=model.predict(x_test)plt.scatter(x_test,y_test,)plt.plot(x_test,y_pred,'r')plt.show() 20/20 [==============================] - 0s 1ms/step 123456789101112# 正规方程求解(没有添加偏置)def normal(x, y): #theta = np.linalg.inv(X.T@X)@X.T@y#X.T@X等价于X.T.dot(X) theta =np.linalg.inv(x.T.dot(x)).dot(x.T).dot(y) return thetatheta=normal(np.array(x_train).reshape(80,1),y_train)# 可视化plt.scatter(x_test,y_test)y_pred= np.array(x_test)*thetaplt.plot(x_test,y_pred,'r')plt.show() 逻辑回归 1234import numpy as npfrom keras.models import Sequentialfrom keras.layers import Denseimport keras 123456789101112131415#生成数据x_train = np.random.random((1000, 20))y_train = np.random.randint(2,size=(1000,1))x_test = np.random.random((100, 20))y_test = np.random.randint(2, size=(100, 1))model = Sequential()model.add(Dense(1,activation='sigmoid',input_dim=20))model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])cost = model.fit(x_train,y_train,epochs=20,callbacks=cbks,validation_data=(x_test, y_test),batch_size=128)score = model.evaluate(x_test, y_test, batch_size=128)score 神经网络 123456from keras.models import Sequentialfrom keras.layers import Dense, Dropout, Activationfrom keras.optimizers import SGDimport tensorflow as tfimport kerasimport numpy as np C:\Users\DataMesh\Anaconda3\envs\py3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters Using TensorFlow backend. 123456789101112131415161718192021x_train = np.random.random((1000, 20))y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)x_test = np.random.random((100, 20))y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)print(x_train.shape,y_train.shape)model = Sequential()model.add(Dense(64, activation='relu', input_dim=20))model.add(Dropout(0.5))model.add(Dense(10, activation='softmax'))sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])model.fit(x_train, y_train, epochs=20, batch_size=128)score = model.evaluate(x_test, y_test, batch_size=128)model.summary() (1000, 20) (1000, 10) Epoch 1/20 1000/1000 [==============================] - 0s 313us/step - loss: 2.3688 - acc: 0.0980 Epoch 2/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3446 - acc: 0.1000 Epoch 3/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3213 - acc: 0.1250 Epoch 4/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3287 - acc: 0.1100 Epoch 5/20 1000/1000 [==============================] - 0s 21us/step - loss: 2.3065 - acc: 0.1140 Epoch 6/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3219 - acc: 0.1000 Epoch 7/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3094 - acc: 0.1180 Epoch 8/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.3052 - acc: 0.1100 Epoch 9/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.2990 - acc: 0.1370 Epoch 10/20 1000/1000 [==============================] - 0s 18us/step - loss: 2.2996 - acc: 0.1190 Epoch 11/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.2975 - acc: 0.1320 Epoch 12/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.3026 - acc: 0.1090 Epoch 13/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.2979 - acc: 0.1130 Epoch 14/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.2977 - acc: 0.1200 Epoch 15/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.2874 - acc: 0.1100 Epoch 16/20 1000/1000 [==============================] - 0s 21us/step - loss: 2.2853 - acc: 0.1390 Epoch 17/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.2897 - acc: 0.1330 Epoch 18/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.2823 - acc: 0.1380 Epoch 19/20 1000/1000 [==============================] - 0s 18us/step - loss: 2.2890 - acc: 0.1290 Epoch 20/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.2891 - acc: 0.1260 100/100 [==============================] - 0s 420us/step _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_3 (Dense) (None, 64) 1344 _________________________________________________________________ dropout_2 (Dropout) (None, 64) 0 _________________________________________________________________ dense_4 (Dense) (None, 10) 650 ================================================================= Total params: 1,994 Trainable params: 1,994 Non-trainable params: 0 _________________________________________________________________ 启动tensorboard，代码中加入 123456789tb_cb=keras.callbacks.TensorBoard(log_dir=&apos;./logs&apos;, histogram_freq=1, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)cbks=[];cbks.append(tb_cb);model.fit(x_train, y_train, epochs=20, batch_size=128, verbose=0, validation_split=0.2, callbacks=cbks)]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>keras 深度学习 机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[透过《头号玩家》看未来世界]]></title>
    <url>%2F2018%2F05%2F07%2Fplay-one%2F</url>
    <content type="text"><![CDATA[人类从众多动物中胜出，靠的是虚构的故事来组织大规模协作。想要破解人类的未来，必须先破解这种虚构的力量。狩猎时代倾向泛灵论，就在于人能否存活，取决于周遭动物，因此各种图腾成了协作的虚构。农业时代，人类脱离与动物天择的规则，有神论渐渐占据主导，寄希望于各种神灵负责风调雨顺。随着科技对自然法则的认识，现代人文主义崛起，认为人应该跟随自己的内心，做自己喜欢的事。随着大数据人工智能的崛起，发现这种人类独有的情感也是一种算法，通过基因以及化学物质就可以控制心灵，自已意志其实是生物体自身算法演化的结果，于是未来的人会通过基因检测，心理测试以及各种能够趋利避害的手段改造自身。整个世界将被算法所掌控，人只在未来世界中提供数据作为算法的来源。于是急需找到一种人类存活的意义，AR的出现也许是一种新的虚构力量。 《头号玩家》剧情无疑设置在未来。属于人类由自由意志转向虚拟现实的过度时期，除了做出对未来的预测外，还承载着现在人文主义的观点。人工智能的发展，必将撇下进化及其缓慢有性生殖，正如有性生殖撇下无性生殖一样，现在硅这种物种突变速度明显胜过碳基的生命，也许如我们不关心花草树木的想法一样，未来硅晶片物种将人类体验视同数据模式，再不关心人类自身的意义所在，但这也同时提供人类不会被智能所消灭的证据，无氧生物目前的生存就是最好的证明，而连接人类与智能之间的恐怕就是VR这种虚拟现实。 在这种过度期人类偶尔还是会塑造出文化意义，电影导演作为70高龄的老人，在行将就木之前想通过一部对未来的思考影片表达自己的内心诉求。第一关卡，告诉我们游戏世界完全不同于现实，在绿洲只要你够想象力，比如过关是使劲的后退而不是现实的一往直前，或许他也要传达的是退一步海阔天空，人生何必那么争抢好胜。第二关哈利迪就是将现实中一直深爱却没勇气迈出那一步的遗憾带入游戏设定，每个人生或许都会经历这种无奈，体会着至爱带来的撕心裂肺，只能借以无尽的遗憾来麻痹自己。第三关告诉我们人生如游戏，不必争强好胜，重在人生体验，活好当下快乐幸福每一天才是存在的意义。作为主打彩蛋的电影，自然不放过电影的终极意义，最后也是给主角一颗大彩蛋，才免于被反派枪杀，因为反派曾作为实习生建议哈利迪这种设定。剧终落幕，留下虚拟只是虚拟，现实才应该是我们体验的地方。 也许就是这样一个虚拟世界，将扛起人类重建未来意义的大旗，拯救失去权威的人类，奔向那个只要想象力的绿洲。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>未来世界</tag>
        <tag>虚拟现实</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异步和多线程]]></title>
    <url>%2F2018%2F05%2F07%2Fprogramming-think%2F</url>
    <content type="text"><![CDATA[编程语言模型思考之异步和多线程 各种类型的编程语言在解决特定领域问题上具有独有的编程模型，例如异步模型和多线程模型，语言最初设计者考虑哪种模型至关重要 目的：不管哪种模型，其目的是为了程序的运行可持续性，也就是多任务执行解决方案。不能因为某些任务一直阻塞，而其资源（主要CPU）处于不工作状态，因此衡量一个语言的优劣，大部分评论文章针对是否充分利用处理器，以及对于编程人员在该模型上编程的易用性 两种模型的比较 异步模型：不论是操作系统还是语言运行库所提供的异步模型，为了不阻塞程序运行，对于一些耗时不确定的响应比较长时的操作可注册一个回调，为了管理这些回调处理完后的通知，一般语言运行库（比如js）提供事件编程模型，或者操作系统（异步IO）直接支持，其背后原理是行事件的任务所在进程或线程提供调度策略，轮询频率以及任务优先级都交由事件调度完成。因为这种情况下不会阻塞，所以理论上一个逻辑控制流（一个cpu核充分利用）足已，而且对于资源的访问由于是单个的顺序访问，因此很适合对于资源操作建模，不如js对于dom的操作，java swing对于UI的双事件机制，redis对于内存的控制。其缺点是代码层面的可读性，要面对回调地狱问题，js常见很多层回调，java swing监听内部类的化会更复杂，由于纯面向对象编程，用一个回调函数非得封装成类来传入，导致好多代码，只不过java其他地方没有那么多回调需求而已，庆幸的是这类语言会陆续更新一些高级的语法糖，java8推出一系列面向函数式编程的特性：lambda表达式，高阶函数，方法引用，FutureCompletable异步等来全面拥抱新的编程生态。js 的promise以及c#最先推出的async/await可谓是回调天堂。随着多核硬件的技术发展，这种模型已不太能充分利用硬件优势，有些模型会采取迂回措施，比如redis可以启动多个进程，资源控制用slot编号控制，Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。 多线程模型：其实我这里表达的不太准确，应该是逻辑控制流不在是上述一条，而是至少两条以上，也就是并发，多线程只是并发的其一种解决方案。操作系统在单核cpu上通过时间片轮换来实现，此处不考虑时间片轮换实现的进程，因为进程本质上资源隔离，不在此讨论范畴。同样为了多任务不阻塞，充分利用资源（cpu）,在该模型下将耗时操作新开一个线程，主调方程序完全以同步代码执行且无阻塞，可是新开线程的状态管理成了很大问题，甚至不可控，java 实现runable()接口的新线程其返回值和其中的异常都丢失，当然可以用callable()改善。线程间通信可通过共享对象完成，因此有及其复杂的同步控制还有各种锁来达到程序出错，还有一种解决方案，这些共享对象在web编程中大多数都已经持久化，其复杂的资源控制转移到数据库管理。只有java编程高手才能轻松驾驭这些模型。那这种复杂编程模型换来的优势就是在多核cpu或者超线程（一个核提供两并行逻辑流）上能物尽其用，能充分发挥硬件能力，因此后端语言大多选用此模型。随着语言的更新，java推出的线程池其在调度策略上的不可控（系统级线程实现，调度由操作提供）有所改善，防止无用线程的空转，其ForkJoin池更是能将任务几乎平均在各个线程中并行。由于线程创建所需资源依然很大，而线程池的解决方案对于编程人员来说依然很复杂。于是协程（可看做在线程上的子线程）应用而生，大多数程序执行时通过线程栈压栈出栈操作，本地方法栈一经弹出，其上下文立马摧毁，协程切换必须要实现这种能保存上下文环境的方法，以便之后恢复，并在语言层运行库上支持调度，python js 的Generator/yield就提供这种支持，当然支持闭包的语言其实在函数栈弹出后也会保存环境（函数式语言的coniuenation不只有返回值，任意时间点都能保存），go语言便是将协程亲民化的最好实现，协程与线程的比例为M:N,只需要go关键字就可以轻松的开启新的协程，其channel更是轻松的实现协程间的通信，及其易于编程服务器高并发程序。由于操作系统提供线程 调度，那共享同一个线程的所有协程也共享同样的调度策略，一般协程携带的代码片段可看成在一些队列里，新开线程或者重用空闲线程来执行他们，但是这种协作式调度依然对于资源的控制还是要加锁理论上不如直接的事件驱动+合理的线程池 来的快。go的goroutine目的是简化代码逻辑，而不是使程序运行的更快，随着其运行库的不断发展和完善，其性能一定会越来越好，尤其是在CPU核数越来越多的未来，终有一天我们会为了代码的简洁和可维护性而放弃那一点点性能的差别。 后记 并发编程就这样结束了吗？上述是针对cpu有限，尽可能挖掘其利用率的解决方案，对于目前分布式下动不动成千上万节点的并发又该如何处理？Akka框架是自管理+消息通信，自管理意味着各个节点自己处理自己的收到的消息，然后通过发送消息来通信，或者新开一个子节点，各个父节点管理各自的子节点，当某些节点挂掉后重建节点，消息不可达时重复发送消息。这就要求代码片段易于分割重建以及不变性，于是函数式编程大行其道，这种情况下通过消息通信的机制来避免竞态条件而不再是精确控制资源。在面向对象里调用方控制着被调用的对象，Actor这种模式只管与消息的通信，解决了很多并发的难点，正如Akka官方所说We believe that writing correct concurrent, fault-tolerantand scalable applications is too hard.Most of the time it’s because we are using the wrong tools and the wrong level of abstraction. —— Akka， 之所以并发这么难，就是用了错误的抽象。随着廉价的硬件资源增多，软件解决方案又再次发生改变。这种模式已经大量运用在容器以及微服务管理上，以前的并发控制单一资源，现在都是复制副本以便可以创建新的节点，用廉价易得的空间换取着宝贵的时间。 举个栗子：公司晨会后，领导给每个人下达任务，并不等一个人完成后在去给其他人下达，而是我们都说OK后，领导干其他事去了，等我们干完活了再通知领导做出下一步指使，领导异步工作。后来人员增多，需要再增加一个二领导同时协助下达任务，两个领导并行工作。再到后来公司规模无限大，领导也没精力亲力亲为下达任务了，每个人每天只处理自己受到的邮件任务，这便是第三种模式。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>异步</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言介绍]]></title>
    <url>%2F2018%2F05%2F07%2Fgo%2F</url>
    <content type="text"><![CDATA[go语言特性介绍 go是一门支持并发编程和内存垃圾回收的编译型静态类型语言 go是以软件工程为目的的语言设计，同大多数通用型编程语言相比，清晰简洁高效 1. 清晰的依赖关系 1. 清晰的语法 1. 清晰的语义 1. 偏向组合而不是继承 1. 编程模型（垃圾回收、并发）的简单性 1. 易于为它编写工具（gotool/gofmt/godoc/gofix） 依赖处理 在编译阶段，将未被使用的依赖视为错误 import 导入代码而不是整个库，清晰依赖关系要比代码重用重要 语法命名 语法就是编程语言的用户界面 首字母大写：名字对于包使用者可见 其余：名字对于包使用者不可见 并发 不要通过共享内存来通信，要通过通信来共享内存 要组合，不要继承 面向对象支持：允许添加方法到任意类型，没有类型体系 接口组合 错误 if和return处理错误 1234f, err := os.Open(fileName)if err != nil &#123; return err&#125; 工具 gofmt 格式化代码 gofix 重构 包与导入导出 每个 Go 程序都是由包构成的 程序从 main 包开始运行 按照约定，包名与导入路径的最后一个元素一致 -使用分组导入语句是更好的形式 1234import ( &quot;fmt&quot; &quot;math&quot;) 在 Go 中，如果一个名字以大写字母开头，那么它就是已导出的 在导入一个包时，你只能引用其中已导出的名字 函数 类型在变量名之后 函数可以返回任意数量的返回值 函数也是值。它们可以像其它值一样传递 函数值可以用作函数的参数或返回值 123func swap(x, y string) (string, string) &#123; return y, x&#125; – 在使用闭包访问外部变量的时候，问问你自己这个变量时候会发生改变，这样的改变对闭包的运行有什么影响。 变量 var 语句用于声明一个变量列表 var 语句可以出现在包或函数级别 在函数中，简洁赋值语句 := 可在类型明确的地方代替 var 声明 基本类型 123456789boolstringint int8 int16 int32 int64uint uint8 uint16 uint32 uint64 uintptrbyte // uint8 的别名rune // int32 的别名 // 表示一个 Unicode 码点float32 float64complex64 complex128 零值 数值类型为 0 布尔类型为 false 字符串为 “”（空字符串） 表达式 T(v) 将值 v 转换为类型 T 常量的声明与变量类似，只不过是使用 const 关键字 零值是非常有用的。如 bytes.Buffer的文档所述 “Buffer 的零值是一个准备好了的空缓冲。” 类似的，sync.Mutex 也没有明确的构造函数或 Init 方法。取而代之，sync.Mutex 的零值被定义为非锁定的互斥量。 for 基本的 for 循环由三部分组成，它们用分号隔开： 初始化语句：在第一次迭代前执行(可选) 条件表达式：在每次迭代前求值（false退出） 后置语句：在每次迭代的结尾执行（可选） 无限循环 12for &#123;&#125; if同 for 一样， if 语句可以在条件表达式前执行一个简单的语句 switch 是编写一连串 if - else 语句的简便方法。它运行第一个值等于条件表达式的 case 语句 switch 的 case 语句从上到下顺次执行，直到匹配成功时停止 没有条件的 switch 同 switch true 一样。这种形式能将一长串 if-then-else 写得更加清晰 1234567891011 func main() &#123; t := time.Now() switch &#123; case t.Hour() &lt; 12: fmt.Println(&quot;Good morning!&quot;) case t.Hour() &lt; 17: fmt.Println(&quot;Good afternoon.&quot;) default: fmt.Println(&quot;Good evening.&quot;) &#125;&#125; defer 使用规则（golang当中，defer代码块会在函数调用链表中增加一个函数调用。这个函数调用不是普通的函数调用，而是会在函数正常返回，也就是return之后添加一个函数调用。因此，defer通常用来释放函数内部变量。） defer被声明时，其参数就会被实时解析 defer执行顺序为先进后出 defer可以读取有名返回值 指针 类型 *T 是指向 T 类型值的指针。其零值为 nil &amp; 操作符会生成一个指向其操作数的指针 操作符表示指针指向的底层值 结构体 一个结构体（struct）就是一个字段的集合 结构体字段使用点号来访问 结构体字段可以通过结构体指针来访问p := &amp;v p.X = 1e9 1234v1 = Vertex&#123;1, 2&#125; // has type Vertexv2 = Vertex&#123;X: 1&#125; // Y:0 is implicitv3 = Vertex&#123;&#125; // X:0 and Y:0p = &amp;Vertex&#123;1, 2&#125; // has type *Vertex 数组与切片 类型 [n]T 表示拥有 n 个 T 类型的值的数组 类型 []T 表示一个元素类型为 T 的切片 切片通过两个下标来界定，即一个上界和一个下界，二者以冒号分隔 切片就像数组的引用 在进行切片时，你可以利用它的默认行为来忽略上下界 切片 s 的长度和容量可通过表达式 len(s) 和 cap(s) 来获取 切片可以用内建函数 make 来创建 a := make([]int, 5) // len(a)=5 为切片追加新的元素是种常用的操作，为此 Go 提供了内建的 append 函数func append(s []T, vs ...T) []T for 循环的 range 形式可遍历切片或映射 map 映射的文法与结构体相似，不过必须有键名 在映射 m 中插入或修改元素m[key] = elem 获取元素 elem = m[key] 删除元素delete(m, key) 通过双赋值检测某个键是否存在 elem, ok = m[key] 方法 Go 没有类。不过你可以为结构体类型定义方法 方法就是一类带特殊的 接收者 参数的函数 方法只是个带接收者参数的函数 就是接收者的类型定义和方法声明必须在同一包内；不能为内建类型声明方法 你可以为指针接收者声明方法 带指针参数的函数必须接受一个指针 而以指针为接收者的方法被调用时，接收者既能为值又能为指针（传值无区别，调用有区别） 使用指针接收者的原因有二： 首先，方法能够修改其接收者指向的值 其次，这样可以避免在每次调用方法时复制该值 接口 接口类型 是由一组方法签名定义的集合 接口类型的值可以保存任何实现了这些方法的值 隐式接口从接口的实现中解耦了定义，这样接口的实现可以出现在任何包中，无需提前准备 在内部，接口值可以看做包含值和具体类型的元组(value, type)接口值调用方法时会执行其底层类型的同名方法 即便接口内的具体值为 nil，方法仍然会被 nil 接收者调用,在一些语言中，这会触发一个空指针异常,Go 中通常会写一些方法来优雅地处理它 1234567func (t *T) M() &#123; if t == nil &#123; fmt.Println(&quot;&lt;nil&gt;&quot;) return &#125; fmt.Println(t.S)&#125; nil 接口值既不保存值也不保存具体类型 指定了零个方法的接口值被称为 空接口：interface{} 类型断言 提供了访问接口值底层具体值的方式。t := i.(T)``t, ok := i.(T)//不会panic 类型选择 是一种按顺序从几个类型断言中选择分支的结构 12345678switch v := i.(type) &#123;case T: // v 的类型为 Tcase S: // v 的类型为 Sdefault: // 没有匹配，v 与 i 的类型相同&#125; fmt 包中定义的 Stringer 是最普遍的接口之一 123type Stringer interface &#123; String() string&#125; error 123type error interface &#123; Error() string&#125; 通常函数会返回一个 error 值，调用的它的代码应当判断这个错误是否等于 nil 来进行错误处理 123456i, err := strconv.Atoi(&quot;42&quot;)if err != nil &#123; fmt.Printf(&quot;couldn&apos;t convert number: %v\n&quot;, err) return&#125;fmt.Println(&quot;Converted integer:&quot;, i) io.Reader 接口有一个 Read 方法 1func (T) Read(b []byte) (n int, err error) 在遇到数据流的结尾时，它会返回一个 io.EOF 错误 goroutine Go 运行时管理的轻量级线程 go go f(x, y, z) 会启动一个新的 Go 程并执行,x, y 和 z 的求值发生在当前的 Go 程中，而 f 的执行发生在新的 Go 程中。 信道是带有类型的管道，你可以通过它用信道操作符 &lt;- 来发送或者接收值 12ch &lt;- v // 将 v 发送至信道 ch。v := &lt;-ch // 从 ch 接收值并赋予 v。 和映射与切片一样，信道在使用前必须创建ch := make(chan int) 默认情况下，发送和接收操作在另一端准备好之前都会阻塞。这使得 Go 程可以在没有显式的锁或竞态变量的情况下进行同步 信道可以是 带缓冲的。将缓冲长度作为第二个参数提供给 make 来初始化一个带缓冲的信道ch := make(chan int, 100) 仅当信道的缓冲区填满后，向其发送数据时才会阻塞。当缓冲区为空时，接受方会阻塞 接收者可以通过为接收表达式分配第二个参数来测试信道是否被关闭：若没有值可以接收且信道已被关闭，那么在执行完v, ok := &lt;-ch ok 会被设置为 false。 循环 for i := range c会不断从信道接收值，直到它被关闭 select 语句使一个 Go 程可以等待多个通信操作 select 会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时会随机选择一个执行 为了在尝试发送或者接收时不发生阻塞，可使用 default 分支 123456select &#123;case i := &lt;-c: // 使用 idefault: // 从 c 中接收会阻塞时执行&#125; sync.Mutex Go 标准库中提供了 sync.Mutex 互斥锁类型及其两个方法Lock Unlock 可以通过在代码前调用 Lock 方法，在代码后调用 Unlock 方法来保证一段代码的互斥执行 可以用 defer 语句来保证互斥锁一定会被解锁 12345678910111213141516171819202122232425262728293031// SafeCounter 的并发使用是安全的。type SafeCounter struct &#123; v map[string]int mux sync.Mutex&#125;// Inc 增加给定 key 的计数器的值。func (c *SafeCounter) Inc(key string) &#123; c.mux.Lock() // Lock 之后同一时刻只有一个 goroutine 能访问 c.v c.v[key]++ c.mux.Unlock()&#125;// Value 返回给定 key 的计数器的当前值。func (c *SafeCounter) Value(key string) int &#123; c.mux.Lock() // Lock 之后同一时刻只有一个 goroutine 能访问 c.v defer c.mux.Unlock() return c.v[key]&#125;func main() &#123; c := SafeCounter&#123;v: make(map[string]int)&#125; for i := 0; i &lt; 1000; i++ &#123; go c.Inc(&quot;somekey&quot;) &#125; time.Sleep(time.Second) fmt.Println(c.Value(&quot;somekey&quot;))&#125; web服务 目前主流的web服务：REST/SOAP 网络进程三元组（ip地址，协议，端口） 其他 %+v 打印包括字段在内的实例的完整信息 %#v 打印包括字段和限定类型名称在内的实例的完整信息 %T 打印某个类型的完整说明]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程]]></title>
    <url>%2F2018%2F05%2F07%2Fthread%2F</url>
    <content type="text"><![CDATA[多任务 多任务：操作系统可以同时运行多个任务。 进程：指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆栈等组成的，是一个能独立运行的活动实体。 线程：线程是进程中的一个实体，作为系统调度和分派的基本单位。 解决方案： 1.启动多个进程 2.启动多个线程 3.多进程+多线程 如何调度进程和线程，完全由操作系统决定，程序自己不能决定什么时候执行，执行多长时间。 计算密集型 vs. IO密集型 计算密集型任务的特点是要进行大量的计算，消耗CPU资源，，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。 第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少。合理的线程数计算公式： Nthreads = NCPU * UCPU * (1 + W/C) 其中：NCPU=Runtime.getRuntime().availableProcessors()cpu核心数,UCPU利用率在（0,1）之间，w/C为w等待时长和计算时长的比值 并行和并发 并发是两个任务共享时间段，并行则是两个任务在同一时间发生，比如运行在多核 CPU上。如果一个程序要运行两个任务，并且只有一个 CPU 给它们分配了不同的时间片，那么这就是并发，而不是并行。 多线程优点 1.资源利用更好 2.程序响应更快 多线程代价 1.增加资源消耗，上下文切换开销 2.设计更复杂，对于共享资源的控制 竞态条件与临界区 竞态条件：当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。 临界区：导致竞态条件发生的代码区称作临界区。 如何避免：在临界区中使用适当的同步就可以避免竞态条件。 在同一程序中运行多个线程本身不会导致问题，问题在于多个线程访问了相同的资源。如，同一内存区（变量，数组，或对象）、系统（数据库，web services等）或文件。实际上，这些问题只有在一或多个线程向这些资源做了写操作时才有可能发生，只要资源没有发生变化,多个线程读取相同的资源就是安全的。 java多线程 一个线程的生命周期 创建一个线程 Java 提供了三种创建线程的方法： 通过实现 Runnable 接口； 12345 public class MyRunnable implements Runnable &#123; public void run()&#123; System.out.println("MyRunnable running"); &#125;&#125; 通过继承 Thread 类本身； 12345 public class MyThread extends Thread &#123; public void run()&#123; System.out.println("MyThread running"); &#125;&#125; 通过 Callable 和 Future 创建线程。 创建线程的三种方式的对比 采用实现 Runnable、Callable 接口的方式创见多线程时，线程类只是实现了 Runnable 接口或 Callable 接口，还可以继承其他类。 使用继承 Thread 类的方式创建多线程时，编写简单，如果需要访问当前线程，则无需使用 Thread.currentThread() 方法，直接使用 this 即可获得当前线程。 Thread 方法 下表列出了Thread类的一些重要方法： 1234567891011121314151617序号 方法描述1 public void start()使该线程开始执行；Java 虚拟机调用该线程的 run 方法。2 public void run()如果该线程是使用独立的 Runnable 运行对象构造的，则调用该 Runnable 对象的 run 方法；否则，该方法不执行任何操作并返回。3 public final void setName(String name)改变线程名称，使之与参数 name 相同。4 public final void setPriority(int priority) 更改线程的优先级。5 public final void setDaemon(boolean on)将该线程标记为守护线程或用户线程。6 public final void join(long millisec)等待该线程终止的时间最长为 millis 毫秒。7 public void interrupt()中断线程。8 public final boolean isAlive()测试线程是否处于活动状态。 上述方法是被Thread对象调用的。下面的方法是Thread类的静态方法。 1234567891011序号 方法描述1 public static void yield()暂停当前正在执行的线程对象，并执行其他线程。2 public static void sleep(long millisec)在指定的毫秒数内让当前正在执行的线程休眠（暂停执行），此操作受到系统计时器和调度程序精度和准确性的影响。3 public static boolean holdsLock(Object x)当且仅当当前线程在指定的对象上保持监视器锁时，才返回 true。4 public static Thread currentThread()返回对当前正在执行的线程对象的引用。5 public static void dumpStack()将当前线程的堆栈跟踪打印至标准错误流。 java 同步 Java 同步块（synchronized block）用来标记方法或者代码块是同步的。Java 同步块用来避免竞争。Java 中的同步块用 synchronized 标记。同步块在 Java 中是同步在某个对象上。所有同步在一个对象上的同步块在同时只能被一个线程进入并执行操作。所有其他等待进入该同步块的线程将被阻塞，直到执行该同步块中的线程退出。 线程通信 1. 通过共享对象通信 1. 忙等待 1. wait()，notify()和 notifyAll() 1. 不要对常量字符串或全局对象调用 wait()，在 wait()/notify()机制中，不要使用全局对象，字符串常量等。应该使用对应唯一的对象 1. 丢失的信号 为了避免信号丢失， 用一个变量来保存是否被通知过。在 notify 前，设置自己已经被通知过。在 wait 后，设置自己没有被通知过，需要等待通知 1. 假唤醒(由于莫名其妙的原因，线程有可能在没有调用过 notify()和 notifyAll()的情况下醒来)解决为添加while判断，以下代码为最佳实践 123456789101112131415161718192021222324public class PoolThread &#123; MonitorObject myMonitorObject = new MonitorObject(); boolean wasSignalled = false; public void doWait() &#123; synchronized (myMonitorObject) &#123; while (!wasSignalled) &#123; try &#123; myMonitorObject.wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; //clear signal and continue running. wasSignalled = false; &#125; &#125; public void doNotify() &#123; synchronized (myMonitorObject) &#123; wasSignalled = true; myMonitorObject.notify(); &#125; &#125;&#125; 管程 (英语：Monitors，也称为监视器) 是对多个工作线程实现互斥访问共享资源的对象或模块。这些共享资源一般是硬件设备或一群变量。管程实现了在一个时间点，最多只有一个线程在执行它的某个子程序 避免死锁 加锁顺序 加锁时限 死锁检测 阻塞与非阻塞算法 阻塞算法：阻塞线程直到请求操作可以被执行例如，java.util.concurrent.BlockingQueue阻塞数据结构 非阻塞算法：通知请求线程操作不能够被执行，并返回（AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference 都是非阻塞数据结构） 非阻塞算法的好处： 当一个线程请求不能够被执行时，不再阻塞，请求线程有一个自由选择 一个线程阻塞不会引起其他线程挂起，不会发生死锁（活锁依然会产生） 由于挂起的线程切换较少，性能提高 如果线程阻塞，将会竞争下一轮的notify，如果不阻塞，将会更快的执行 Volatile 变量 olatile 变量最新的值总是对跑在其他 CPU 上的线程可见。其他线程每次会从主存中读取变量的值，而不是比如线程所运行 CPU 的 CPU 缓存中。（可见性，并不保证原子性） 单线程写，多线程读 123456789public class SingleWriterCounter &#123; private volatile long count=0; public void inc()&#123; this.count++; &#125; public long getCount()&#123; return this.count; &#125;&#125; 只有一个线程调用inc()（单线程保证原子性）,多个线程调用getCount()（Volatile可见性保证）,线程安全，上述数据机构可以衍生多个volatile变量，只需保证只有一个线程写即可 多线程写 如果确实需要多线程写一个变量，必须同步 1234567private long count=0;public synchronized void inc()&#123; this.count++;&#125;public synchronized long getCount()&#123; return this.count;&#125; 更好的方式：java原子变量来代替上述同步方法() 12345678910111213private AtomicLong count = new AtomicLong(0);public void inc() &#123; boolean updated = false; while (!updated) &#123; long prevCount = this.count.get(); updated = this.count.compareAndSet(prevCount, prevCount + 1); &#125;&#125;public long getCount() &#123; return this.count.get();&#125; 上述代码compareAndSet是一个原子操作，如果操作失败，将会进入下次循环（自旋），直到操作成功，这部分代码并未加锁，称为乐观锁，乐观假定只有一个线程操作，如果有多个线程同时操作，会丢弃目前线程所获取到的值，但是任然不使用锁。可想而知，乐观锁适用于共享内存不是很高的场景，如果共享的数据结构有多个变量，可用AtomicReference 来达到目的，但是，如果数据结构非常复杂，比如很长的队列，也不适用于此场景 CAS CAS（Compare and swap）比较和替换是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量的值。适用java提供的cas可在硬件层面是支持，运行代码更快 ABA问题 A-B-A 问题指的是一个变量被从 A 修改到了 B，然后又被修改回 A 的一种情景。其他线程对于这种情况却一无所知。 解决：增加类似版本或者计数器的变量。java提供AtomicStampedReference 类 1234567891011121314151617181920 public static class IntendedModification &#123; public AtomicBoolean completed = new AtomicBoolean(false);&#125;private AtomicStampedReference&lt;IntendedModification&gt; ongoinMod = new AtomicStampedReference&lt;IntendedModification&gt;(new IntendedModification(), 0);public void modify() &#123; boolean modified = false; while (!modified) &#123; IntendedModification currentlyOngoingMod = ongoinMod.getReference(); int stamp = ongoinMod.getStamp(); IntendedModification newMod = new IntendedModification(); newMod.completed = new AtomicBoolean(true); modified = ongoinMod.compareAndSet(currentlyOngoingMod, newMod, stamp, stamp + 1); &#125;&#125; 上述非阻塞算法Java 已经提供了实现，ConcurrentLinkedQueue（offer(E e) 将指定元素插入此队列的尾部。poll() 获取并移除此队列的头，如果此队列为空，则返回 null。） 同步器 众多同步器（锁，信号量，阻塞队列）用来保护临界区的代码，其实现会包含下列部分过程 状态 访问条件 状态变化 通知策略 Test-and-Set 方法（或者set方法） 饥饿和公平 Java 中导致饥饿的原因 高优先级线程吞噬所有的低优先级线程的 CPU 时间 线程被永久堵塞在一个等待进入同步块的状态 线程在等待一个本身(在其上调用 wait())也处于永久等待完成的对象 在 Java 中实现公平性方案，需要: 使用锁，而不是同步块。 公平锁。 注意性能方面。 Slipped Conditions：所谓 Slipped conditions，就是说， 从一个线程检查某一特定条件到该线程操作此条件期间，这个条件已经被其它线程改变，导致第一个线程在该条件上执行了错误的操作 代码实践 Semaphore Semaphore(int count):创建拥有count个许可证的信号量 acquire()/acquire(int num):获取1/num个许可证 release()/release(int num):释放1/num个许可证 123456789101112131415161718192021222324252627282930313233public class SeDemo &#123; public static void main(String[] args) &#123; Semaphore semaphore = new Semaphore(2); Person a = new Person(semaphore, "A"); Person b = new Person(semaphore, "B"); Person c = new Person(semaphore, "C"); a.start(); b.start(); c.start(); &#125;&#125;class Person extends Thread &#123; private Semaphore semaphore; public Person(Semaphore semaphore, String name) &#123; this.semaphore = semaphore; setName(name); &#125; public void run() &#123; System.out.println(getName() + "is waitng..."); try &#123; semaphore.acquire(); System.out.println(getName() + "is servering..."); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(getName() + "is done!"); semaphore.release(); &#125;&#125; CoundDownLatch CountDownLatch(int count):必须发生count个数量才可以打开锁存器 await();等待锁存器 contDown():触发事件 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class CDDemo &#123; public static void main(String[] args) &#123; CountDownLatch countDownLatch = new CountDownLatch(3); new Racer(countDownLatch, "A").start(); new Racer(countDownLatch, "B").start(); new Racer(countDownLatch, "C").start(); for (int i = 0; i &lt; 3; i++) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(3 - i); countDownLatch.countDown(); if (i == 2) &#123; System.out.println("start"); &#125; &#125; &#125;&#125;class Racer extends Thread &#123; private final CountDownLatch countDownLatch; public Racer(CountDownLatch countDownLatch, String name) &#123; this.countDownLatch = countDownLatch; setName(name); &#125; @Override public void run() &#123; try &#123; countDownLatch.await(); for (int i = 0; i &lt; 3; i++) &#123; System.out.println(getName() + ":" + i); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; CyclicBarrier CyclicBarrier(int num):等待线程的数量 cyclicBarrier(int num,Runnable action):等待线程的数量以及所有线程到达后的操作 await():到达临界点后暂停线程 12345678910111213141516171819202122232425262728293031323334public class CDDemo &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3, new Runnable() &#123; @Override public void run() &#123; System.out.println("game start"); &#125; &#125;); new Player(cyclicBarrier, "A").start(); new Player(cyclicBarrier, "B").start(); //new Player(cyclicBarrier,"C").start(); &#125;&#125;class Player extends Thread &#123; private CyclicBarrier cyclicBarrier; public Player(CyclicBarrier cyclicBarrier, String name) &#123; setName(name); this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Exchanger Exchanger&lt;v&gt;:指定进行交换的数据类型 V exchange(V object):等待线程到达，交换数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445 class A extends Thread &#123; private Exchanger&lt;String&gt; ex; public A(Exchanger&lt;String&gt; ex) &#123; this.ex = ex; &#125; @Override public void run() &#123; String str = null; try &#123; str = ex.exchange("Hello"); System.out.println(getName() + ":" + str); str = ex.exchange("world"); System.out.println(getName() + ":" + str); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class B extends Thread &#123; private Exchanger&lt;String&gt; ex; public B(Exchanger&lt;String&gt; ex) &#123; this.ex = ex; &#125; @Override public void run() &#123; String str = null; try &#123; str = ex.exchange("Hi"); System.out.println(getName() + ":" + str); str = ex.exchange("worldB"); System.out.println(getName() + ":" + str); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Phaser Phaser()/Phaser(int num); 使用指定0/num个party创建Phaser register():注册party arriveAndAdvance()：到达时等待所有party到达 arriveAndDeregister(): 到达时注销线程自己 12345678910111213141516171819202122232425262728293031323334353637383940414243public class PDemo &#123; public static void main(String[] args) &#123; Phaser phaser = new Phaser(1); System.out.println("starting..."); new Worker(phaser, "fuwuyuan").start(); new Worker(phaser, "chushi").start(); new Worker(phaser, "shangcaiyuan").start(); for (int i = 0; i &lt;= 3; i++) &#123; phaser.arriveAndAwaitAdvance(); System.out.println("Order" + i + "finished"); &#125; phaser.arriveAndDeregister(); &#125;&#125;class Worker extends Thread &#123; private Phaser phaser; public Worker(Phaser phaser, String name) &#123; setName(name); this.phaser = phaser; phaser.register(); &#125; @Override public void run() &#123; for (int i = 0; i &lt;= 3; i++) &#123; System.out.println("curent ordrer is :" + getName() + i); if (i == 3) &#123; phaser.arriveAndDeregister(); &#125; else &#123; phaser.arriveAndAwaitAdvance(); &#125; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 执行器 用于启动并控制线程的执行 核心接口为Executor，包含一个execute(Runnable)用于指定被执行的线程 ExecuteService接口用于控制线程执行和管理线程 ThreadPoolEcecutor/ScheduledThreadPoolExecutor/ForkJoinPool Callable&lt;v&gt;:表示具有返回值的线程 Future&lt;V&gt;:表示Callable的返回值 12345678910111213141516171819202122232425262728293031323334 public class ExecutorDemo &#123; public static void main(String[] args) &#123; ExecutorService es = Executors.newFixedThreadPool(2); Future&lt;Integer&gt; result1 = es.submit(new Task(1, 50)); Future&lt;Integer&gt; result2 = es.submit(new Task(50, 101)); try &#123; System.out.println(result1.get() + result2.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class Task implements Callable&lt;Integer&gt; &#123; private int begin; private int end; public Task(int begin, int end) &#123; this.begin = begin; this.end = end; &#125; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i = begin; i &lt; end; i++) &#123; sum += i; &#125; return sum; &#125;&#125; lock用法 12345678910class Data&#123; int i=0; Lock lock= new ReentrantLock(); void operate()&#123; lock.lock(); i++; System.out.println(i); lock.unlock(); &#125;&#125; java ForkJoinPool使用 1234567891011121314151617181920212223242526272829303132333435363738394041public class ForkDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask&lt;Long&gt; result = forkJoinPool.submit(new MTask(0, 100000001)); System.out.println(result.get()); &#125;&#125;class MTask extends RecursiveTask&lt;Long&gt; &#123; private int begin, end; static final int M = 1000; public MTask(int begin, int end) &#123; this.begin = begin; this.end = end; &#125; @Override protected Long compute() &#123; long sum = 0; if (end - begin &lt;= M) &#123; for (int i = begin; i &lt; end; i++) &#123; sum += i; &#125; &#125; else &#123; int mid = (begin + end) / 2; MTask left = new MTask(begin, mid); left.fork(); MTask right = new MTask(mid + 1, end); right.fork(); Long r1 = left.join(); Long r2 = right.join(); sum = r1 + r2; &#125; return sum; &#125;&#125; 线程池 在Java中，线程池的概念是Executor这个接口，具体实现为ThreadPoolExecutor类 构造参数 int corePoolSize =&gt; 该线程池中核心线程数最大值 int maximumPoolSize该线程池中线程总数最大值 long keepAliveTime非核心线程闲置超时时长 TimeUnit unit keepAliveTime的单位，TimeUnit是一个枚举类型 BlockingQueue workQueue该线程池中的任务队列：维护着等待执行的Runnable对象 常用的workQueue类型： SynchronousQueue：这个队列接收到任务的时候，会直接提交给线程处理，而不保留它，如果所有线程都在工作怎么办？那就新建一个线程来处理这个任务！所以为了保证不出现&lt;线程数达到了maximumPoolSize而不能新建线程&gt;的错误，使用这个类型队列的时候，maximumPoolSize一般指定成Integer.MAX_VALUE，即无限大 LinkedBlockingQueue：这个队列接收到任务的时候，如果当前线程数小于核心线程数，则新建线程(核心线程)处理任务；如果当前线程数等于核心线程数，则进入队列等待。由于这个队列没有最大值限制，即所有超过核心线程数的任务都将被添加到队列中，这也就导致了maximumPoolSize的设定失效，因为总线程数永远不会超过corePoolSize ArrayBlockingQueue：可以限定队列的长度，接收到任务的时候，如果没有达到corePoolSize的值，则新建线程(核心线程)执行任务，如果达到了，则入队等候，如果队列已满，则新建线程(非核心线程)执行任务，又如果总线程数到了maximumPoolSize，并且队列也满了，则发生错误 DelayQueue：队列内元素必须实现Delayed接口，这就意味着你传进去的任务必须先实现Delayed接口。这个队列接收到任务时，首先先入队，只有达到了指定的延时时间，才会执行任务 ThreadPoolExecutor.execute(Runnable command)添加任务 常见四种线程池，Java通过Executors提供了四种线程池，这四种线程池都是直接或间接配置ThreadPoolExecutor的参数实现的 CachedThreadPool()线程数无限制 FixedThreadPool()固定线程数超出的线程会在队列中等待 ScheduledThreadPool()支持定时及周期性任务执行 SingleThreadExecutor()所有任务按照指定顺序执行，即遵循队列的入队出队规则 AQS 维护着一个volatile int state 和一个FIFO线程等待队列 acquire 12345while(synchronization state does not allow acquire)&#123; enqueue current thread if not already quened; plssible blok current thread;&#125;dequene current thread if it was queued; release 1234update synchronization state;if (state may permit a blocked thread to acqire)&#123; unblock one or more queued threads&#125; AQS在功能上有独占控制和共享控制两种功能 备注 什么是线程安全的代码？（不具有原子性的代码都不是线程安全的） 线程逃逸规则 （如果一个资源（对象，数组，文件，数据库连接，套接字）的创建，使用，销毁（销毁”指不再有引用指向对象）都在同一个线程内完成，且永远不会脱离该线程的控制，则该资源的使用就是线程安全的。） “不变”（Immutable）和“只读”（Read Only）是不同的。当一个变量是“只读”时，变量的值不能直接改变，但是可以在其它变量发生改变的时候发生改变。 自旋锁是为了防止假唤醒(下面while),wasSignalled是为了防止唤醒过期 123456789101112131415161718192021222324public class MyWaitNotify3&#123;MonitorObject myMonitorObject = new MonitorObject();boolean wasSignalled = false;public void doWait()&#123; synchronized(myMonitorObject)&#123; while(!wasSignalled)&#123; try&#123; myMonitorObject.wait(); &#125; catch(InterruptedException e)&#123;...&#125; &#125; //clear signal and continue running. wasSignalled = false; &#125;&#125;public void doNotify()&#123; synchronized(myMonitorObject)&#123; wasSignalled = true; myMonitorObject.notify(); &#125;&#125;&#125;]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keras命令速记]]></title>
    <url>%2F2018%2F05%2F07%2Fpython_keras%2F</url>
    <content type="text"><![CDATA[准备 安装anaconda 12345678conda create -n py3 python=3 activate py3deactivate py3conda install packgenameconda install tensorflowconda install keras tensorboard --logdir=/full_path_to_your_logs callbacks=[TensorBoard(log_dir=&apos;./log_dir&apos;)]]]></content>
      <categories>
        <category>笔记速记</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性代数]]></title>
    <url>%2F2018%2F05%2F07%2Fline%2F</url>
    <content type="text"><![CDATA[笛卡尔平面直角坐标系：如果这坐标系看成是点的空间，那每个点都有坐标（x,y），从原点到（x,y）的有向线段为向量a(x,y),那这个空间中的点最少用几个怎么样关系的向量，然后通过向量运算得出呢，答案是只要不共线的两向量（非线性），这个空间也称为这两向量张成的空间。i(1,0)和j(0,1)便是符合标准之一，称为基底，特别的，这两向量正交ij=0(向量点积为0)，向量长度为1（欧几里得范数），变成了标准正交向量 矩阵：想象这个平面，对它进行各种变换，有三种情况： 4. 它还是一个平面，只不过发生着拉伸旋转等（二维） 它变成一条线，此时原来平面上的向量有的成了点，有的依然是向量（一维） 既然能变成线，在变换一下变成了点（零维） 那这种变换怎么表示呢，如果有了表示是不是研究这种表示的性质可以控制平面变换呢？这种表示就是矩阵，现在要把矩阵当成动词（对空间的变换）来看待了 线性相关：如果一组向量中的 任意一个向量都不能表示成其他向量的线性组合，那么这组向量被称为 线性无关。如果某个向量是一组向量中某些向量的线性组合，那么我 们将这个向量加入到这组向量后不会增加这组向量的生成子空间。 线性变换后原点不变，关系不变（直线依然是直线，平行的依然平行） 列空间：把二维矩阵看成两个列向量，这两个列向量的线性组合，就构成了A的列空间（列向量张成的空间） 零矩阵：将空间缩成一个点 单位矩阵：平面经过I=((1,0),(0,1))（二维单位矩阵）后，横向拉伸1，纵向拉伸1，原平面不变，于是有A=AI 逆矩阵：平面经过变换后只要是上述情况2.1，就可以逆向的变换回来，情况2.2存在信息丢失，好多个平面都可以变成直线，因此变不回来了，情况2.3信息丢失更严重，于是以下公式容易理解了 inv(A)A=I 其中inv(A)是A的逆矩阵 （这辈子你都忘不了这个公式了，对平面操作之后逆向操作，等于没操作） 行列式：考虑平面上原来面积为1的图形，变换后面积增大的倍率就是行列式的意义,如果平面经过变换后成直线或者点，那么行列式det=0 对角矩阵：diag(2,3)分别沿着x,y扩大2，3倍，面积扩大6倍，行列式det=6 点积：两个矩阵点积就是两个操作，先进行a操作，在进行b操作，当然和先进行b操作，后进行a操作不一样了，于是矩阵左乘右乘结果当然不一样了，不满足交换律 秩：线性变换后空间的维数，称之为秩rank()。秩与列数相等，称为满秩矩阵 零空间：变换后压缩到原点的向量集合，称为零空间 非奇异矩阵：如果变换后空间没有被扁平化，可逆，称为非奇异矩阵 奇异矩阵，当变换矩阵线性相关，变换后成为一维直线，秩为1，此时矩阵称为奇异矩阵，这个时候必定有向量成了零向量，且零向量的维度为1 维数定理：对于m*n的矩阵A列数=秩+零向量的维数 n=dim Ker(A) + rank(A) 特征向量：是指与 A 相乘后相当于对该向量进行缩放的非零向量 v 1234567 标量 λ 被称为这个特征向量对应的 特征值 构建具有特定特征值和特征向量的矩阵，能够使我们在目标方向上延伸空间 A = Vdiag(λ)inv(V)18. 奇异分解： ``` A = UDV⊤ 假设 A 是一个 m×n 的矩阵，那么 U 是一个 m×m 的矩阵，D 是一个 m×n 的矩阵，V 是一个 n × n 矩阵。矩阵 U 和 V 都被定义为正交矩阵，而矩阵 D 被定义为对角矩阵，对角矩阵 D 对角线上的元素被称为矩阵 A 的 奇异值。矩阵 U的列向量被称为 左奇异向量，矩阵 V 的列向量被称 右奇异 向量。SVD 最有用的一个性质可能是拓展矩阵求逆到非方矩阵 伪逆： 12345678 其中，矩阵 U，D 和 V 是矩阵 A奇异值分解后得到的矩阵。对角矩阵 D 的伪逆D+ 是其非零元素取倒数之后再转置得到的。 当矩阵 A 的列数多于行数时，使用伪逆求解线性方程是众多可能解法中的一 种。特别地，x = A+y 是方程所有可行解中欧几里得范数 ∥x∥2 最小的一个。 当矩阵 A 的行数多于列数时，可能没有解。在这种情况下，通过伪逆得到的 x 使得 Ax 和 y 的欧几里得距离 ∥Ax−y∥2 最小20. 矮矩阵与长矩阵：以上都是方阵，行数小于列数的矮矩阵，实际上是将一个高维向量压缩到低纬度，有无穷解，行数大于列数的长矩阵，低纬度向高维转化，仅当向量恰好在低维度所在的空间里有解21. 求解Ax=b：两边左乘逆 ``` inv(A)Ax=b Ix=inv(A)b x=inv(A)b 这便是线性方程解法，当然，逆有可能不存在 唯一解：就是向量x,经过线性变化后就是向量b,自然这种变换要求变换后还是平面，及行列式det!=0 无穷多个解： 如果变换后成直线且与b向量共线，变换前与b向量相对应的事特解，变换前与被压缩成点成为零向量的向量是通解，这些线性相关的零空间解加特解就是通解 无解：如果变换后成直线且落不到b向量上，那就无解了 求解方程步骤：当逆变换存在时，用逆变换求解方程，当逆变换不存在，等价于行列式为0，看b向量是否落在A列空间里了 方程是否有解：在长矩阵中，为了使方程 Ax = b 对于任意向量 b ∈ Rm 都存在解，我们要求 A 的列空间构 成整个 Rm。如果 Rm 中的某个点不在 A 的列空间中，那么该点对应的 b 会使得 该方程没有解。矩阵 A 的列空间是整个 Rm 的要求，意味着 A 至少有 m 列，即 n ≥ m。否则，A 列空间的维数会小于 m。例如，假设 A 是一个 3 × 2 的矩阵。目 标 b 是 3 维的，但是 x 只有 2 维。所以无论如何修改 x 的值，也只能描绘出 R3 空 间中的二维平面。当且仅当向量 b 在该二维平面中时，该方程有解。不等式 n ≥ m 仅是方程对每一点都有解的必要条件。这不是一个充分条件，因 为有些列向量可能是冗余的。假设有一个 R2×2中的矩阵，它的两个列向量是相同 的。那么它的列空间和它的一个列向量作为矩阵的列空间是一样的。换言之，虽然 该矩阵有 2 列，但是它的列空间仍然只是一条线，不能涵盖整个 R2 空间。 以上都基于二维分析，高维分析时可类似考虑]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数学知识</tag>
        <tag>线性代数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git命令速记]]></title>
    <url>%2F2018%2F05%2F07%2Fgit%2F</url>
    <content type="text"><![CDATA[git笔记 通过点击页面右上角的’Fork’按钮来分叉[项目存储库] 从你的GitHub账户克隆scikit-learn repo的分支到你的本地磁盘 12$ git clone git@github.com：YourLogin / scikit-learn.git$ cd scikit-learn 创建一个feature分支来保存你的发展变化 1git checkout -b my-feature 在您的功能分支上开发功能。使用git add git commit添加文件： 12$ git add modified_files$ git commit 在Git中记录您的更改，然后将更改推送到您的GitHub帐户 1$ git push -u origin my-feature ​ ## 常用命令 1234567891011121314151617181920212223242526272829git initgit addgit commit -m &quot;&quot;git statusgit diffgit loggit log --pretty=onlinegit log --graph --pretty=oneline --abbrev-commitgit reset --hard HEAD^git reset --hard 版本号git refloggit diff HEAD -- readme.txt git checkout -- filegit rmgit push -u origin mastergit remote add origin git@github.com:michaelliao/learngit.gitgit checkout -b dev ==git branch dev + git checkout devgit checkout -b dev origin/devgit branchgit merge devgit merge --no-ff -m &quot;merge with no-ff&quot; devgit branch -d devgit stashgit stash popgit branch -D feature-vulcangit remotegit branch --set-upstream dev origin/devgit pullgit tag v1.0 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，版本回退，不过前提是没有推送到远程库 查看分支：git branch 创建分支：git branch &lt;name&gt; 切换分支：git checkout &lt;name&gt; 创建+切换分支：git checkout -b &lt;name&gt; 合并某分支到当前分支：git merge &lt;name&gt; 删除分支：git branch -d &lt;name&gt; 查看远程库信息，使用git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch --set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 补充提交git commit --amend 撤销上次提交git reset --soft HEAD~ 撤销上次提交和暂存区git reset --mixed HEAD~ 撤销所有，整体回到上次修改get reset --hard HEAD~ 将文件从暂存区撤回git reset HEAD readme.txt 撤销文件的修改git checkout -- readme.md git flow 创建develop分支 12git branch developgit push -u origin develop 开始新Feature分支 123456git checkout -b feature/1 developgit push -u origin feature/1git statusgit add some-filegit commit 完成feature分支 1234567git pull origin developgit checkout developgit merge -no-ff feature/1git push origin developgit branch -d feature/1git push origin --delete feature/1 开始release 1git checkout -b release-1.0 develop 完成release 1234567891011121314git checkout mastergit merge -no-ff release-1.0git pushgit checkout developgit merge --no-ff release-1.0git push git branch -d release-1.0git push origin --delete release-1.0git tag -a v1.0 mastergit push --tags 开始Hotfix 1git checkout -b hotfix-1.0 master 完成hotfix 1234567891011git checkout mastergit merge --no-ff hotfix-1.0git pushgit checkout developgit merge --no-ff hotfix-1.0git pushgit branch -d hotfix-1.0git tag -a v1.0 mastergit push --tags 合并 git merge --squash dev git commit -m “”]]></content>
      <categories>
        <category>笔记速记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员看经济]]></title>
    <url>%2F2018%2F05%2F07%2Feconomy%2F</url>
    <content type="text"><![CDATA[我们可以将人类文明快进一下： 1.刚开变成人的时候，大家都各自为王，自给自足，A部落肥羊三千，顿顿吃荤，B家族良田五亩，天天绿色食品，过着幸福的生活 2.过了几百年，大家都吃腻了，于是约了个地方，你提羊来我送菜，荤素结合，过上了幸福的生活 3.又过了几百年，A家族不仅吃的饱，还想穿C家族的裤头，但C是出家人，于是顺手牵着羊跟B换了青菜，拿着青菜换裤头穿，这样子大家都很麻烦，交易成本太高了，于是后来A就拿羊从X那里换了块石头，这石头带着方便，而且大家都认可，还能存着，想穿裤头就去找和尚换。这石头后来只有金色的大家才认可，于是又过上了幸福的生活 4.又过了几百年，有个100单位金子的S商人自己开一家店，花了10个金子建造房子（固有资产），90个金子借给那些急需要的人，报酬是还回来的除了本金，还要加点小小的金石头，这下没钱的乐坏了，过了几年，大家都来借钱，余额不足，S想了一个办法，大家可以把石头放进来，要用的时候还能在额外多给些小石头，这下有钱的乐坏了，于是S靠收到的额外的金子减去支出的金子剩下的利润活着。如果没有S,有idea但没钱的那些家伙就只能干着急，所以S极大的促进了社会生产力，资本经济就是好，从此大家都过着幸福的生活 5.很多人听说S很能赚钱，大家都纷纷效仿，可这个时候某一个出了状况，比如某家把所有的金钱都放出去了，有人来取钱，竟然说没钱，大家一传十，十传百，都很恐慌，蜂拥来取钱，实际情况是，他们所能给的钱远远小于人家当时存的钱，因为部分放出去了嘛。造成的后果就是他们纷纷倒闭，人民也苦不堪言。（银行挤兑） 6.大家去找县长，这种事发生的多了，县长也有经验了，为了防止人民取不出来钱，县长告诉所有S,要想开店，就得交一部分金子来，（存款储备金）好出事了我分给大家，维持社会安定 7.当然上述情况S也想了办法，就是把羊画在纸上（各种票据），承诺自己见到票据也会兑换金子，同时在多给些小金子（贴现），要是有很多在诱惑下选择相信，那么他们彼此之间也可以用票据进行交易。这样子大家都有自己造票据，相信的人也很有限，于是县长把自己的头像画在纸上，强制大家使用，也过着幸福的生活 8.这个县长一心为民，随着生产力的提高，产品也会越来越多，如果县长的纸币不增加的画，那就会通货物紧缩，于是县长就加班生产纸币，但也不能加太多，不然物价也会上涨。这个时候县长和S其实干的事一样的事情，只不过县长大公无私，不赚取利益，若果市场萧条，有idea的N人贷不到款，实现不了自己的理想，也是社会的损失，于是县长就会降低给S的利率，自然S也会N降低利率，这样市场欣欣向荣，于是，那种小毛贼idea也很多啊，他们也能轻易的贷款，结果啥也不干，本金也还不了了，这是整个社会的损失。为防止弱鸡也玩这种游戏，于是县长又提高了利率，均衡在县长手里。可能你要问了，县长大公无私，收取利率算怎么回事。想想县长有必要吗，人家真要用钱，自己多生产去了，收取的东西他也会平衡整个市场进行销毁或者在流通，大家过上了幸福的生活 （未完待续，下次写todo） 资产=负债+所有者权益 利润=收入-支出 权责发生制，收付制记账 会记科目计算及意义]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>经济漫谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 命令速记]]></title>
    <url>%2F2018%2F05%2F07%2Fdocker%2F</url>
    <content type="text"><![CDATA[Docker for Beginners 安装 在Alpine Linux容器中运行单个任务docker container run alpine hostname 列出所有容器docker container ls --all 列出正在运行的容器 docker container ls 运行Docker容器并访问其shelldocker container run --interactive --tty --rm ubuntu bash –interactive 说你想要一个互动会话。 –tty 分配一个伪tty。 –rm 告诉Docker继续操作并在完成执行时移除容器。 键入exit退出shell会话。这将终止bash进程，导致容器退出exit 运行新的MySQL容器docker container run --detach --name mydb -e MYSQL_ROOT_PASSWORD=my-secret-pw mysql:latest 显示了MySQL Docker容器中的日志docker container logs mydb 容器内运行的进程docker container top mydb 连接到已经运行的容器中的新shell进程 docker exec -it mydb sh 使用Dockerfile中的说明创建新的Docker镜像docker image build --tag $DOCKERID/linux_tweet_app:1.0 . 从镜像启动一个新的容器docker container run --detach --publish 80:80 --name linux_tweet_app $DOCKERID/linux_tweet_app:1.0 优雅地停止容器 docker container stop 启动容器docker start dockker_name 删除 docker container rm 强制删除 docker container rm --force linux_tweet_app – 查看镜像docker image ls 挂载目录到容器 docker container run --detach --publish 80:80 --name linux_tweet_app --mount type=bind,source=&quot;$(pwd)&quot;,target=/usr/share/nginx/html $DOCKERID/linux_tweet_app:1.0 docker container run --detach --publish 27017:27017 --name heuristic_shtern --mount type=bind,source=&quot;c:/data/db/&quot;,target=/data/db/ mongo 搜索Docker主机上的镜像docker image ls -f reference=&quot;$DOCKERID/*&quot; 在推送图像之前，您需要登录Docker Hubdocker login提供Docker ID凭据后推送docker image push $DOCKERID/linux_tweet_app:1.0,浏览https://hub.docker.com/r/&lt;your docker id&gt;/ docker镜像检索docker search 镜像名字 删除指定镜像docker rmi image-id 挂载数据文件docker run -p 27017:27017 -i -v /c/data/db:/data/db -d mongo 挂载卷docker container run -v HOST_PATH:CONTAINER_PATH [OPTIONS] IMAGE [CMD] 创建volumedocker volume create --name html 挂载volunedocker container run --name www -d -p 8080:80 -v html:/usr/share/nginx/html nginx 列出网络brctl show 查找网络docker network inspect bridge 测试网络ping -c5 172.17.0.2 拉取镜像docker image pull alpine 启动交互式容器docker container run -it alpine /bin/sh 运行容器后创建镜像docker container commit CONTAINER_ID 标记镜像docker image tag &lt;IMAGE_ID&gt; ourfiglet]]></content>
      <categories>
        <category>笔记速记</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据整理]]></title>
    <url>%2F2018%2F05%2F07%2Fbig-data%2F</url>
    <content type="text"><![CDATA[这是最好的时代，也是最坏的时代。 --狄更斯 ABC时代：ABC即人工智能（AI）、大数据（Big Data）、云计算（Cloud Computing）三个词语的英文首字母缩写，这三个领域已然成为当下最为热门的三大领域。 4V特征： 海量化（volumes） 多样化（variety） 快速化（velocity） 价值化（value） 舍恩伯格在《大数据时代》中指出，面对大数据人类的思维和认知要发生转变： 全样本（不是随机抽样） 概率化（不迷恋精确性） 相关性（次化因果关系） 按照业务处理实时性划分为实时处理和批处理，按照系统功能及侧重点划分为侧重数据保存的存储性系统和侧重数据分析的密集型计算系统 大数据离不开分布式和集群技术，因此系统间通信必不可少 基于分层的结构（TCP/IP,各个系统中几乎都有用到分层的概念） 基于对象的结构（RPC，rest也算是一种低性能rpc通信） 基于数据的结构（web，经常传递各种含有数据的java bean） 基于消息的结构（ESB,各种MQ） 分布式的目的是避免单点故障，提高可靠性（HA,在P的情况下选择A还是C?）,所以数据都是有大量副本存在的，副本在各个节点存放的典型算法有哈希算法，按照数据量存放，按照数据范围存放等。既然有多个副本，保证一致性协议有中心副本控制协议（Primary-secondary协议或Master-slaver）和去中心化副本控制协议（Paxos算法），对于Hadoop生态来说，普遍采用中心化简化系统，但为了可靠性，又在zookeeper中采用去中心化选举出primary节点后，转为中心化 进程间通信IPC有管道，套接字，共享内存涉及IO有 阻塞式同步、非阻塞式同步、多路复用同步模式以及异步模式 典型超级计算机系统结构 并行向量处理（PVP） 对称式多处理器（SMP） 分布式共享内存（DSM） 大规模并行处理（MPP） 缓存系统中常用的策略 LFU:淘汰最不常用的 LRU:淘汰最近最少使用 ARC:LRU和LRU结合 其他基于时间的淘汰策略 ETL:Extraction-Transformation-Loading的缩写，中文名为数据抽取、转换和加载。ETL负责将分布的、异构数据源中的数据如关系数据、平面数据文件等抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础。ETL是BI项目中最重要的一个环节，通常情况下ETL会花掉整个项目的1/3的时间，ETL设计的好坏直接关系到BI项目的成败。ETL也是一个长期的过程，只有不断地发现问题并解决问题，才能使ETL运行效率更高，为项目后期开发提供准确数据。 Hadoop生态 - HDFS分布式文件系统 checkpoint 读写文件 YARN统一资源管理框架 MapReduce分布式计算框架 Zookeeper分布式集群协调系统 Hive数据仓库工具 Hbase分布式列式数据库 storm实时流处理]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据之Spark]]></title>
    <url>%2F2018%2F05%2F07%2FSpark%2F</url>
    <content type="text"><![CDATA[概览 Apache Spark是一个高效的通用的集群计算系统。 它提供高层级的Java, Scala 和 Python 接口，和优化的通用图计算引擎。 同时支持丰富的高级工具集，如处理SQL和结 构化数据的 Spark SQL ，机器学习 MLlib，图处理的 GraphX ，和 Spark Streaming。 速度 比内存中的HadoopMapReduce快10倍 比硬盘上的HadoopMapReduce快100 倍 Spark 有一个高级的 DAG 执行引擎，支持循环迭代的数据流和内存中的计算 易用 用 Java、Scala 或者 Python 迅速开发应用 通用 Spark提供一套高层工具栈，包括 SparkSQL，机器学习的MLlib，GraphX，和 Spark Streaming。你可以在一个应用中无缝地结合这些框架。 集成 Hadoop Spark也很容 易独立运行，可以读取任 何Hadoop数据源 下载 Spark 官网下载：https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz Maven依赖： 123groupId: org.apache.sparkartifactId: spark-core_2.11version: 2.2.0 运行 1234567#使用 --master参数指定 一个分部式系统的主URL，或者 local指定本地单线程运行， 或 local[N]指定本地N线程。#Scala ./bin/spark-shell --master local[2]#Python./bin/pyspark --master local[2]#通用的 spark-submit 脚本来启动示例程序./bin/spark-submit examples/src/main/python/pi.py 10 为了看起来简洁，以下均为Python解释运行 1234567891011121314151617$ ./bin/pyspark --master local&gt;&gt;&gt; textFile = sc.textFile(&quot;README.md&quot;)&gt;&gt;&gt; textFile.count()104&gt;&gt;&gt; textFile.first()u&apos;# Apache Spark&apos;&gt;&gt;&gt; linesWithSpark = textFile.filter(lambda line : &quot;Spark&quot; in line)&gt;&gt;&gt; linesWithSpark.count()20&gt;&gt;&gt; textFile.map(lambda line : len (line.split())).reduce(lambda a, b : a if ( a&gt;b)else b)22&gt;&gt;&gt; wordCounts = textFile.flatMap(lambda line : line.split()).map(lambda word : ( word , 1 )).reduceByKey(lambda a , b : a + b )&gt;&gt;&gt; wordCounts.collect()&gt;&gt;&gt; linesWithSpark.cache()&gt;&gt;&gt; linesWithSpark.count()20 maven项目 1234567891011121314151617181920212223242526package com.spark.practice;import org.apache.spark.SparkConf;import org.apache.spark.api.java.JavaRDD;import org.apache.spark.api.java.JavaSparkContext;import org.apache.spark.api.java.function.Function;public class SimpleApp &#123; public static void main(String[] args) &#123; String logFile = &quot;/Users/wyq/spark/spark-2.1.1-bin-hadoop2.6/README.md&quot;;// 可以是你系统上任意的英文txt文件 SparkConf conf = new SparkConf().setAppName(&quot;Simple Application&quot;).setMaster(&quot;local&quot;); JavaSparkContext sc = new JavaSparkContext(conf); JavaRDD&lt;String&gt; logData = sc.textFile(logFile).cache(); long numAs = logData.filter(new Function&lt;String, Boolean&gt;() &#123; public Boolean call(String s) &#123; return s.contains(&quot;a&quot;); &#125; &#125;).count(); long numBs = logData.filter(new Function&lt;String, Boolean&gt;() &#123; public Boolean call(String s) &#123; return s.contains(&quot;b&quot;); &#125; &#125;).count(); System.out.println(&quot;Lines with a: &quot; + numAs + &quot;, lines with b: &quot; + numBs); &#125;&#125; 运行结果：Lines with a: 62, lines with b: 30 架构及原理 每一个 Spark 应用程序都包含一个 驱动程序(driver program)，它会运行 用户的 main函数，并在集群上执行各种 并行操作(parallel operations)。Spark 提供的最 主要的抽象概念是 弹性分布式数据集(resilient distributed dataset) (RDD)， 它是一个元 素集合，被分区地分布到集群的不同节点上，可以并行操作。RDDs可以从 HDFS(或者 任意其他支持 Hadoop 的文件系统) 上的一个文件开始创建，或者通过转换驱动程序 (driver program)中已经存在的 Scala 集合得到。 用户也可以让 Spark 将一个 RDD持 久化(persist)到内存中，使其能在并行操作中被有效地重复使用。最后，RDD能自动从节点 故障中恢复。 Spark 的第二个抽象概念是共享变量(shared variables)，它可以在并行操作中使用。 在默认情况下，当 Spark 将一个函数以任务集(a set of tasks)的形式在不同节点上并行运 行时， 会将该函数所使用的每个变量的拷贝传递给每一个任务(task)中。有时候，一个 变量需要在任务之间，或任务与驱动程序之间进行共享。 Spark 支持两种类型的共享变 量: 广播变量(broadcast variables)，它可以在所有节点的内存中缓存一个值;累加器 (accumulators):只能用于做加法的变量，例如计数器(counters)或求和器(sums)。 RDD RDDs 支持两种操作:转换(transformations)和 动作(actions) 所有转换都是 惰性的(lazy) 可以使用 持久化(persist)(或者 缓存(cache) )方法，把一个 RDD 持久化 (persist)到内存 转换(Transformation) filter(func) flatMap(func) mapPartitions(func) mapPartitionsWithIndex(func) sample(withReplacement, fraction, seed) union(otherDataset) intersection(otherDataset) distinct([numTasks])) groupByKey([numTasks]) reduceByKey(func, [numTasks]) aggregateByKey(zeroValue)(seqOp, combOp, [numTasks]) sortByKey([ascending], [numTasks]) join(otherDataset, [numTasks]) 动作(Action) reduce(func) collect() count() first() take(n) takeSample(withReplacement, num, [seed]) takeOrdered(n, [ordering]) saveAsTextFile(path) saveAsSequenceFile(path) (Java and Scala) saveAsObjectFile(path) (Java and Scala) countByKey() foreach(func) Spark Streaming Spark Streaming提供了一个称为 离散流 或 DStream的高层次的抽象，它代表一个持 续的流数据 Spark Streaming还提供了 窗口的计算 ，它允许你通过滑动窗口对数据进行转 换 Spark SQL Spark SQL 允许在 Spark 中执行以 SQL、HiveQL 或 Scala 表示的关系型查询语句。 此组件的核心是一种新型的 RDD:SchemaRDD。SchemaRDDs 由行对象(Row objects) 组成，同时还有一个描述每行中列元素数据类型的模式(schema)。一个 SchemaRDD 类 似于一个传统关系型数据库中的表。一 SchemaRDD 可以从现有的 RDD、Parquet 文件， JSON 数据集，或运行 HiveQL 以处理存储在 Apache Hive 中的数据中创建。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM与GC]]></title>
    <url>%2F2018%2F05%2F07%2FJVM%2F</url>
    <content type="text"><![CDATA[JVM体系结构 GC作用在粉红色区域，即方法区和堆 GC算法 常采用两种算法：引用计数算法和基于root根节点图搜索的算法（跟踪算法） 引用算法是每次引用对象计数器加一，gc回收计数为0的对象，缺点是较难处理循环引用（可通过弱软引用解除循环中一方），Python有其实现 跟踪算法从称为gc root的根节点基于图搜索，最后回收不连通图的对象 其中，跟踪算法考虑以下场景 引入：如果现在要清理D:盘可有三种策略： 1.如果无效文件很多，有用文件很少，可将有用文件选定后复制到C:,在格式化D盘，之前文件拷回去 2.如果无效文件很少，有用文件很多，可选定无效文件后直接删除 3.如果2执行好多次以后，比如风景文件夹下有人物照片，人物照片底下有家人照片，这时候可能选择盘下所有的人物照片放到人物文件夹下，相当于整理文件 上述1为复制（copying）,2标记-清除（mark-sweep）,3标记-压缩（mark-compact） gc涉及内存图 1.复制算法发生在新生代（New/Young）,因为大部分对象在伊甸园（Eden）刚创建就夭折了，选取eden,s0存活对象复制到s1(存活1区),回收这两个区，交换两个存活区（也叫from to 区） 2.当对象进行上述1默认15次回收后，对象晋升到old区，或者对象非常大（vip）,将直接在年老代创建，老年到刚开始会实行标记-清理 3.当2进行多次，内存碎片过多，大对象将难以创建，于是实行标记整理到内存一端，留下可用连续空间 根据各代算法应用不同的gc算法，提高gc效率 GC类型 1.Minor GC 针对新生代的GC 2.Major GC 针对旧生代的GC 3.Full GC 针对永久代，新生代，旧生代三者的GC 搜集器 1.串行收集器（serial），顺序搜集，单线程资源好控制，stop the world(stw) 2.并行收集器（parall），并行搜集，回收速度快，资源同步复杂，stop the world 3.并发收集器（Concurrent），不中断应用，资源更为复杂 Young Gen : 均采用复制算法，eden不足时触发，eden官方建议此值为堆的3/8 serial copying:单cpu32位系统client模式均采用此 parallel scavenge:多cpu,64位,server默认模式 parNew：serial copying多线程版本，可搭配cms Old Gen: Serial MSC:串行使用标记清除算法整理算法，client或者32默认 Parallel Compacting:并行标记整理算法，并行标记串行计算对象要移动的地址，最后并行整理，server或者多核默认 Concurrent Mark Sweep(CMS):并发使用标记清除算法，暂停时间短，但相当复杂，GC总时间长，暂停时间主要是发生在GC root 刚开始以及重新标记阶段，算法简述：1串行标记gc root 直达对象（stw）2并发标记可达对象3调整2期间应用产生的新建及变化对象(stw)4并行回收 组合选择 单核小内存单机程序 1-XX:+UseSerialGC 多CPU，吞吐量优先，计算型 12-XX:UseParellGC-XX:UseParellOldGC 多CPU，响应优先，低暂停 12-XX:UseConcMarkSweepGC-XX:ParNewGC 调优 堆：越大越好，过大会增加GC时间和产生垃圾对象，堆每次调整都会发生Full GC,因此一般将以下两值设置为同样大小，但是要预防系统宕机，可将最大堆设置的大点 12-Xms=1024MB:堆的最小值-Xmx=1024MB:堆得最大值 新生代：增大Eden会减低Minor GC的频率，一般固定新生代大小 由于永久代和老年代回收会触发Full GC,尽可能让对象待在survivor 12345-XX:NewSize=1024MB 新生代初始大小-XX:MaxNewSize=1024MB 新生代最大值-XX:NewRadio=m New与Old的比值-Xmn:1024MB 新生代大小-XX:SurvivorRadio=m Eden和Survivor的比值，官方建议8：1，但自己测试好多都是1：1？ 旧生代（随便叫了）：太大，单次GC时间过长，太小，GC频率高 监控 JVM参数 1234-XX:+PrintGC 输出GC简要信息-XX:+PrintGCDetail 输出GC详单-XX:+PrintGCTimeStamps 输出GC时间戳-XX:+PrintGCAppicationStopedTime 输出GC暂停时间 命令行工具 top观察CPU负载 vmstat观察上下文切换 free -m 查看内存 jps 找到java程序的pid jstack主要用来查看某个Java进程内的线程堆栈信息 jmap（Memory Map）和jhat（Java Heap Analysis Tool） dump 用法： jmap -dump:format=b,file=dumpFileName pid jhat查看 ：jhat -port 7000 dumpFileName 浏览器输入host:port 查看 jstat（JVM统计监测工具 1234567S0C、S1C、S0U、S1U：Survivor 0/1区容量（Capacity）和使用量（Used）EC、EU：Eden区容量和使用量OC、OU：年老代容量和使用量PC、PU：永久代容量和使用量YGC、YGT：年轻代GC次数和GC耗时FGC、FGCT：Full GC次数和Full GC耗时GCT：GC总耗时 Jconsole 有以下代码 12345678910public class JvmTest &#123; public static void main(String[] args) throws InterruptedException &#123; List&lt;JvmTest&gt; global = new ArrayList&lt;&gt;(); while (true) &#123; global.add(new JvmTest()); Thread.sleep(1); &#125; &#125;&#125; 一般出现阶梯上升或波形上升时，内存迟早要耗尽，常见的就是全局集合中的对象未释放，如图所示，jvm8移除了持久代，非堆增加了几个概念。 观察以上代码10分钟，分别切换Eden，survivor，old,便能轻易理解垃圾回收的整个过程，由于不停地new对象，因此非堆中的code chche 也逐渐增多。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK各个版本特性介绍]]></title>
    <url>%2F2018%2F05%2F07%2FJDKFurture%2F</url>
    <content type="text"><![CDATA[jdk8 Lambda 表达式 − Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中。 1234567891011121314151617181920212223242526272829package jdk8;public class LambdaPractice &#123; public static void main(String[] args) &#123; MathOperation addition = (int a, int b) -&gt; a + b; MathOperation subtraction = (a, b) -&gt; a - b; MathOperation multiplication = (int a, int b) -&gt; &#123; return a * b; &#125;; MathOperation division = (int a, int b) -&gt; a / b; System.out.println(&quot;60 + 12 = &quot; + operate(60, 12, addition)); System.out.println(&quot;60 - 12 = &quot; + operate(60, 12, subtraction)); System.out.println(&quot;60 x 12 = &quot; + operate(60, 12, multiplication)); System.out.println(&quot;60 / 12 = &quot; + operate(60, 12, division)); &#125; private static int operate(int a, int b, MathOperation mathOperation) &#123; return mathOperation.operation(a, b); &#125;&#125;@FunctionalInterfaceinterface MathOperation &#123; int operation(int a, int b);&#125; 方法引用−方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 1234构造器引用：它的语法是Class::new静态方法引用：它的语法是Class::static_method特定类的任意对象的方法引用：它的语法是Class::method特定对象的方法引用：它的语法是instance::method 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。只需在方法名前面加个default关键字即可实现默认方法 123456789101112131415161718192021222324252627282930313233package jdk8;public class DefaultAndStaticMethod implements A &#123; public static void main(String[] args) &#123; DefaultAndStaticMethod defaultAndStaticMethod = new DefaultAndStaticMethod(); // 调用默认方法 defaultAndStaticMethod.print(); //调用静态方法 A.born(); //调用继承的默认方法 defaultAndStaticMethod.inherit(); &#125; @Override public void inherit() &#123; System.out.println(&quot;继承自A的方法&quot;); &#125;&#125;interface A &#123; default void print() &#123; System.out.println(&quot;我是A默认方法&quot;); &#125; default void inherit() &#123; System.out.println(&quot;我是A需要被继承的方法&quot;); &#125; static void born() &#123; System.out.println(&quot;我是A静态方法&quot;); &#125;&#125; Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 增加了一些新的 IO/NIO 方法，使用这些方法可以从文件或者输入流中获取流（java.util.stream.Stream），通过对流的操作，可以简化文本行处理、目录遍历和文件查找。 新增的 API 如下： BufferedReader.line(): 返回文本行的流 Stream File.lines(Path, Charset):返回文本行的流 Stream File.list(Path): 遍历当前目录下的文件和目录 File.walk(Path, int, FileVisitOption): 遍历某一个目录下的所有文件和指定深度的子目录 File.find(Path, int, BiPredicate, FileVisitOption… ): 查找相应的文件 见http://blog.csdn.net/aloneload/article/details/78091860 Date Time API − 加强对日期与时间的处理。 java.time 中包含了所有关于时钟（Clock），本地日期（LocalDate）、本地时间（LocalTime）、本地日期时间（LocalDateTime）、时区（ZonedDateTime）和持续时间（Duration）的类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class DateTimeApi &#123; public static void main(String[] args) throws InterruptedException &#123; test(); &#125; private static void test() throws InterruptedException &#123; // LocalDate LocalDate localDate = LocalDate.of(2017, Month.OCTOBER, 1);// 2017-10-01 int year = localDate.getYear(); // 2017 Month month = localDate.getMonth(); // OCTOBER int dom = localDate.getDayOfMonth(); // 1 DayOfWeek dow = localDate.getDayOfWeek(); // SUNDAY boolean leap = localDate.isLeapYear(); // false （不是闰年） // LocalTime LocalTime time = LocalTime.of(14, 32); // 14:32 int hour = time.getHour(); // 14 int minute = time.getMinute(); // 32 time = time.withSecond(6); // 14:32:06 time = time.plusMinutes(3); // 20:35:06 // LocalDateTime LocalDateTime localDateTime = LocalDateTime.now(); // of： 静态工厂方法，从组成部分中创建实例 // now： 静态工厂方法，用当前时间创建实例 // parse： 静态工厂方法，总字符串解析得到对象实例 // with： 返回一个部分状态改变了的时间日期对象拷贝 // plus： 返回一个时间增加了的、时间日期对象拷贝 // minus： 返回一个时间减少了的、时间日期对象拷贝 // at： 用当前时间日期对象组合另外一个，创建一个更大或更复杂的时间日期对象 // format： 提供格式化时间日期对象的能力 // Instance时刻 Instant start = Instant.now(); Thread.sleep(1001); Instant end = Instant.now(); System.out.println(&quot;end-start=&quot; + (end.compareTo(start))); // Duration period 时间段 可作为参数进行日期时间的运算 Duration duration = Duration.of(1, ChronoUnit.HOURS); Period period = Period.of(1, 2, 3); System.out.println(duration + period.toString()); // 格式化 DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(&quot;yyyy/MM/dd&quot;); LocalDate localDate2 = LocalDate.parse(&quot;2017/10/01&quot;, dateTimeFormatter); String date = localDate2.format(dateTimeFormatter); System.out.println(); // ZoneId ZoneId zoneId = ZoneId.of(&quot;America/Caracas&quot;); LocalDate date2 = localDate.now(zoneId); System.out.println(date2); &#125;&#125; Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Optional将对象和null包装起来，使得null有迹可循 1234567891011121314151617181920212223242526272829303132333435package jdk8;import java.util.Optional;public class OptionalTest &#123; public static void main(String[] args) &#123; test(); &#125; private static void test() &#123; Optional&lt;String&gt; optional = Optional.of(&quot;java8&quot;); // Optional&lt;String&gt; optional2 = Optional.of(null); 报错 Optional&lt;String&gt; optional2 = Optional.ofNullable(null); String name = optional2.orElse(&quot;default&quot;); System.out.println(&quot;name:&quot; + name);// 输出default // 如果不包装，将得不到有用的信息 // optional2.get();// ava.util.NoSuchElementException: No value present // orElseThrow与orElse方法类似，区别在于返回值。 // orElseThrow抛出由传入的lambda表达式/方法生成异常。 try &#123; optional2.orElseThrow(Exception::new); &#125; catch (Throwable ex) &#123; System.out.println(ex.getMessage()); &#125; // lambda表达式返回值会包装为Optional实例。 Optional&lt;String&gt; upperName = optional.map((value) -&gt; value.toUpperCase()); // 如果满足返回Optional实例值，否则返回空Optional。 Optional&lt;String&gt; longName = optional2.filter((value) -&gt; value.length() &gt; 6); &#125;&#125; Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 1jdeps LambdaPractice.class jdk7 在Switch中可用String 123456789101112String s = &quot;java8&quot;; switch (s) &#123; case &quot;java8&quot;: System.out.println(&quot;java8&quot;); break; case &quot;java7&quot;: System.out.println(&quot;java7&quot;); break; default: System.out.println(&quot;default&quot;); break; &#125; 数值可加下划线用作分隔符（编译时自动被忽略） 1int add=1_342_000; 增强的try 资源管理器自动调用资源的close()函数。和Python里的with语句差不多,再也不用担心忘关资源了 12345678910// try-with-resource try (BufferedReader br = new BufferedReader(new FileReader(&quot;data/nio-data.txt&quot;))) &#123; String line; while((line=br.readLine())!=null) &#123; System.out.println(line); &#125; &#125; catch (IOException|NumberFormatException e) &#123;//此处演示多个异常 e.printStackTrace(); &#125; 另网传的对Java集合（Collections）的增强支持，可直接采用[]、{}的形式存入对象，采用[]的形式按照索引、键值来获取集合中的对象。此特性并不支持 jdk5 自动装箱与拆箱 12int a = 4;Integer b = 5;// 装箱 5-》integer System.out.println(a + b);// 拆箱 //计算 int 的4+5 枚举 单例模式最好的实现 12345678910enum Version &#123; JDK8(8), JDK7(7); private int attibute; public int getAttibute() &#123; return this.attibute; &#125; private Version(int attibute) &#123; this.attibute = attibute; &#125;//使用Version.JDK8.getAttibute();得到属性 静态导入 1import static java.lang.Math.*; 可变参数 123456789101112// 可变参数 private static int sum(int... intlist) &#123; int sum; sum = 0; for (int i = 0; i &lt; intlist.length; i++) &#123; sum += intlist[i]; &#125; return sum; &#125; //System.out.println(sum(1, 2, 3)); //System.out.println(sum(1, 2)); 内省，主要用于操作JavaBean中的属性，通过getXxx/setXxx。一般的做法是通过类Introspector来获取某个对象的BeanInfo信息，然后通过BeanInfo来获取属性的描述器（PropertyDescriptor），通过这个属性描述器就可以获取某个属性对应的getter/setter方法，然后我们就可以通过反射机制来调用这些方法。 1234567People people = new People(1,&quot;zhangsan&quot;); BeanInfo beanInfo=Introspector.getBeanInfo(people.getClass()); PropertyDescriptor[] pds = beanInfo.getPropertyDescriptors(); for (PropertyDescriptor propertyDescriptor : pds) &#123; Object out2 = propertyDescriptor.getReadMethod().invoke(people); System.out.println(out2); &#125; 泛型（包括通配类型/边界类型等） For-Each循环 注解 GitHub：https://github.com/aloneload/JdkFeatures]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>lambda</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数式编程笔记（二）兵马再动]]></title>
    <url>%2F2018%2F05%2F07%2FFP2%2F</url>
    <content type="text"><![CDATA[为什么学习函数式编程 不可变性带来的好处：不会有竞态条件发生，很适合多核分布式下并发；重现使得测试调试非常方便；由于不依赖状态，可实现热部署。 编程生态的变化：各种语言加入lambda表达式（匿名函数），写法上都是类似的箭头表达式（Python是lambda关键字）；声明式编程专注想要得到什么比命令式更细粒度的如何去实现来的简单；函数式编程语言对于数据计算更易理解，比如sql和大数据方面的map,reduce等 高阶函数 需求：计算f(x,y)=xx=yy Java实现： 1234567891011121314public class SumSquare &#123; public static void main(String[] args) &#123; IntFunction&lt;Integer&gt; square = x -&gt; x * x; Supplier&lt;Integer&gt; out = sum_square(square, 3, 4); System.out.println(out.get());//输出25 &#125; private static Supplier&lt;Integer&gt; sum_square(IntFunction square, int a, int b) &#123; return () -&gt; &#123; return (int) square.apply(a) + (int) square.apply(b); &#125;; &#125;&#125; 是不是一头雾水，如果把上述square.apply(a)写成square(a)是不是就有点常规认识的函数调用呢？事实上，在Scala里，函数式编程就是上述的square（a）,此处（）是进行重载得到的（java对基本的运算符不能重载，只能用Function实现的apply方法，但有什么关系，谁又没规定函数调用必须是square（a）,sun认为square.apply(a)是就是喽），但烦人的不仅如此，我猜java不支持模式匹配（类似于switch，但可以匹配更复杂的，比如可匹配函数），于是就定义了各种各种的函数式接口，函数式接口是只有一个方法的接口，实现它就可以以函数为一等公民进行编程（明显是披着函数的对象嘛），比如上述out.get()不接受参数返回表达式，这点从声明的泛型上明显的看出来。那Python里函数是纯纯的好喝的吗（类似c那种），其实只要对象实现__call__方法，那这个对象就是函数，反过来说，一切函数皆对象。至于js里的函数是不是也可以理解成含有apply call bind方法的对象呢,这三可以改变this指向，如果this指向确定（包括宿主环境对象如window对象），可以类似f()调用，如果this不确定，还得使用f.apply(target,…)(target是所属对象)调用。c++函数对象也是重载（）符号完成对象到函数对象的转变（函数指针对于高阶的这两条也能工作的很好）。 进阶三板斧（filter，map,reduce） 需求：筛选十以内的偶数并计算平方和 java： 123456789101112131415161718192021222324252627282930import java.util.stream.Stream;/*v筛选十以内的偶数并计算平方和*/public class FilterMapreduceTest &#123; //java8 以前 private static int sumEven() &#123; int result = 0; for (int i = 1; i &lt; 11; i++) &#123; if (i % 2 == 0) &#123; result += i * i; &#125; &#125; return result; &#125; //java8 private static int newSumEven()&#123; return Stream.iterate(1, i -&gt; i + 1).limit(10)//无限流，惰性求值才有可能产生无限流 // .parallel() //1 .filter(i -&gt; i % 2 == 0) //filter里面是一个谓词高阶函数，返回满足条件的序列 .map(i -&gt; i * i).peek(System.out::println) //map里面是一个高阶函数，每个元素做出映射 .reduce(0, (a, b) -&gt; a + b); //第二个参数是两个参数的高阶函数，归约求和 &#125; //上面两个方法所占代码行数相差无几，但是当业务逻辑比如条件类似sql里where复杂查询时，newSumEven就会体现出代码优势，由于基于流的操作，同时性能也会提高 public static void main(String[] args) &#123; System.out.println(&quot;结果：&quot; + newSumEven()); System.out.println(&quot;传统结果：&quot; + sumEven()); &#125;&#125; 上述代码运行在单线程下，通过添加注释1转为并行流，其背后是fork/join框架，默认线程为核数。流不同于传统的序列操作强大的地方在于其类似流水线的生产方式 1在进行reduce的时候2有可能进行map,10有可能进行filter，也就是说逻辑上只要没有时序关系，他们就有可能并行执行顺序也不确定。可以peek()打印下看每一步的输出，这也是流调试常用的手段。 Python 12345source=range(1,11)sourceFilter=filter(lambda i:i%2==0,source)sourceMap=map(lambda i:i**2,sourceFilter)sourceReduce=reduce(lambda a,b:a+b,sourceMap)print(sourceReduce)//输出220 js中操作dom时数组或集合有很多的高阶函数find(),head(),sort()，foreach()等 1234[1,2,3,4,5,6,7,8,9,10].filter(x=&gt;x%2==0).map(x=&gt;x*x).reduce((a,b)=&gt;a+b,0)//输出220 有了这三板斧，像其他的max(),min(),sum(),first()等等很容易自己就写出来，对于像序列这种操作还有一个非常实用的zip（拉链或者配对）,可用于生成key-value对。 面向对象里多态行为是通过重写实现的，于是GOF的设计模式大行其道，当行为参数化以后，java可以通过匿名类简化具名子类的数量，只是模板代码太多，当支持函数式编程后，好多设计模式都变得异常简单。 来看看经典的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142public class FactoryPatternDemo &#123; public static void main(String[] args) &#123; ShapeFactory shapeFactory = new ShapeFactory(); Shape shape1 = shapeFactory.getShape("CIRCLE"); shape1.draw();//输出Inside Circle::draw() method. Shape shape2 = shapeFactory.getShape("RECTANGLE"); shape2.draw();//输出Inside Rectangle::draw() method. &#125;&#125;interface Shape &#123; void draw();&#125;class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println("Inside Rectangle::draw() method."); &#125;&#125;class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println("Inside Circle::draw() method."); &#125;&#125;class ShapeFactory &#123; //use getShape method to get object of type shape public Shape getShape(String shapeType) &#123; if (shapeType == null) &#123; return null; &#125; if (shapeType.equalsIgnoreCase("CIRCLE")) &#123; return new Circle(); &#125; else if (shapeType.equalsIgnoreCase("RECTANGLE")) &#123; return new Rectangle(); &#125; return null; &#125;&#125; 要想不这么死，就得换个活法 --《绣春刀2》 来看看重构后的代码： 1234567891011121314151617181920212223242526public class FactoryPatternDemo &#123; public static void main(String[] args) &#123; ShapeFactory shapeFactory = new ShapeFactory(); shapeFactory.getShape("CIRCLE").draw();//输出Inside Circle::draw() method. shapeFactory.getShape("RECTANGLE").draw();//输出Inside Rectangle::draw() method. &#125;&#125;interface Shape &#123; void draw();&#125;class ShapeFactory &#123; //use getShape method to get object of type shape public Shape getShape(String shapeType) &#123; if (shapeType == null) &#123; return null; &#125; if (shapeType.equalsIgnoreCase("CIRCLE")) &#123; return ()-&gt;System.out.println("Inside Circle::draw() method."); &#125; else if (shapeType.equalsIgnoreCase("RECTANGLE")) &#123; return ()-&gt; System.out.println("Inside Rectangle::draw() method."); &#125; return null; &#125;&#125; 重构后采用()-&gt; System.out.println(“Inside Rectangle::draw() method.”)直接实现Shape接口，减少代码量 科里化 需求：对于多参数的函数调用能不能分别赋予自变量的值呢 科里化1是一种将具备2个参数(比如，x和y)的函数f转化为使用一个参数的函数g，并 且这个函数的返回值也是一个函数，它会作为新函数的一个参数。后者的返回值和初始函数的 返回值相同，即f(x,y) = (g(x))(y)。 一个经典的页面刷新的例子： 123456789101112131415161718function update(item)&#123; return function (text)&#123; $(&quot;div#&quot;+item).html(text); &#125; &#125; function refresh(url, callback)&#123; var params = ; $.ajax(&#123; type:&quot;post&quot;, url:url, data:&#123; &quot;key&quot; : &quot;value&quot; &#125;, success: function (data, status)&#123; callback(data); &#125; &#125;); &#125; refresh(&quot;url&quot;, update(&quot;div_1&quot;)); 科里化是模块化函数、提高代码重用性的技术。 闭包 需求：js中怎么才能用函数实现对象，即封装属性提供访问接口 闭包：一个拥有许多变量和绑定了这些变量的环境的表达式（通常是一个函数），因而这些变量也是该表达式的一部分。总的来说，支持闭包的语言在函数执行出栈后其中的数据被保留了下来，并没有被gc,java8支持受限的闭包（不能修改非本地变量），js,python,scala均支持闭包 123456 function a(x)&#123; function b(y)&#123;return x+y;&#125; return b;&#125;var c=a(3);c(4); 这里c(4)每次执行时Chrome的闭包显示是a,其中x=3,闭包其实是自由变量x,以及表达式x+y,（chrome显示的a，是其x以及x+y的边界域，感觉a才是真正的闭包域啊），闭包可以保存函数里的数据，所以科里化才变得有意义，要不然每次调用都还是多参数。闭包在js的地位比其他语言更受宠，估计是为了要面向对象，闭包可以很好的实现成员的封装，并提供对外的访问接口，类似setter/getter那样 结合器 需求：实现复合函数，如果有函数f(x),g(x),可以复合为f(g(x))或者g(f(x)) 123456789101112public static void main(String[] args) &#123; Function&lt;Integer,Integer&gt; square=x-&gt;x*x; Function&lt;Integer,Integer&gt; cube=x-&gt;3*x*x*x; Integer result1 = square.compose(cube).apply(2);//compose复合器 Integer result2 = cube.compose(square).apply(2); Integer result3 = square.andThen(x -&gt; 4* x).apply(5);//andThen System.out.println("先cube再square："+result1);//先cube再square：576 System.out.println("先square再cube："+result2);//先square再cube：192 System.out.println("先square再5x："+result3);//先square再5*x：100 &#125; 需要好多步骤处理某种资源，比如拦截器拦截url时，写成这样的.的形式更加的可读代码也很清爽。 递归与迭代 需求：阶乘实现 1234567891011121314151617181920212223242526272829303132//阶乘计算public class Factorial &#123; public static void main(String[] args) &#123; System.out.println("迭代：" + factorialIterative(10)); System.out.println("递归：" + factorialRecursive(10)); System.out.println("尾递归" + factorialHelper(1, 10)); &#125; //迭代式 static int factorialIterative(int n) &#123; int r = 1; for (int i = 1; i &lt;= n; i++) &#123; r *= i; &#125; return r; &#125; //递归式 static long factorialRecursive(long n) &#123; return n == 1 ? 1 : n * factorialRecursive(n - 1); &#125; //尾递归 static long factorialHelper(long acc, long n) &#123; return n == 1 ? acc : factorialHelper(acc * n, n - 1); &#125; //java8 流 static long factorialStreams(long n)&#123; return LongStream.rangeClosed(1, n) .reduce(1, (long a, long b) -&gt; a * b);&#125;&#125; 既然迭代会修改值（比如i++），采用递归又会开启对个嵌套栈，很容易StackOverflow，所以如果把递归放到函数返回，也就是最后一步，并且把记录状态的值传递给它，那么这个函数栈之后也不会使用，可以把它清掉或者新开的函数重用此调用栈，此时就成了伪递归，Scala对此进行了优化Scala，提供的尾递归注解@scala.annotation.tailrec可以帮助我们检查是否是尾递归，很遗憾java目前没有支持，不过可以以流reduce实现它.es6在严格模式下也会开启尾递归优化 持久化数据结构（不可变） 需求：如何保证自己写的程序不会修改意料之外的值呢，函数式编程重在不可变的思想，因此尽量使用不可变的数据结构吧 这里的持久化指的是数据结构的值始终保持一致，不受其他部分变化的影响（而不是保留值到内存或者是硬盘的持久化）。函数式方法不允许修改任何全局数据结构或者任何作为参数传入的参数。 123456789101112131415161718192021222324package studyJava8;import java.util.*;public class Prototype &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; sources = Arrays.asList(1, 7, 5, 4, 6); System.out.println(&quot;函数式更新&quot;+operate2(sources)+&quot;源&quot;+sources); System.out.println(&quot;破坏式操作结果：&quot;+operate(sources)+&quot;源&quot;+sources); //函数式更新[1, 4, 5, 6, 7]源[1, 7, 5, 4, 6]//破坏式操作结果：[1, 4, 5, 6, 7]源[1, 4, 5, 6, 7] &#125; private static List&lt;Integer&gt; operate(List&lt;Integer&gt; sources) &#123; Collections.sort(sources); return sources; &#125; private static List&lt;Integer&gt; operate2(List&lt;Integer&gt; sources) &#123; List&lt;Integer&gt; dest=new ArrayList&lt;&gt;(); dest.addAll(sources); Collections.sort(dest); return dest; &#125;&#125; 可以看到破坏时更新时意外的更新了sources的值，这个例子可能无关痛痒，但如果在多处使用这个值，破坏式更新使得其值已经不可用。所以建议编写程序时使用函数式更新，这个时候原型模式非常有用，也要留意意浅拷贝与深拷贝，如果对象比较大，深度拷贝可使用二进制拷贝加快对象的创建。 模式匹配 需求：还记得数学归纳法吗？ 12f(0) = 1f(n) = n*f(n-1) 能不能根据参数的不同选择不同的函数呢？if-else当然可以，如果情况更加复杂，代码将变得非常复杂，模式匹配可以很好的简化（这里模式匹配并不是正则表达式的匹配）java的switch只支持数值型和String，对于不同函数的选择可以用if-else或者不同的子类通过多态进行选择 123456789101112131415var sign=0val ch:Char=&apos;+&apos;ch match &#123; case &apos;+&apos; =&gt; sign = 1 case &apos;-&apos; =&gt; sign = -1 case _ =&gt; sign = 0 //其他值，相当于switch的default &#125;/*当然Scala里支持类型匹配，数组等序列匹配，更复杂的函数匹配（根据函数签名和返回值的不同选择不同的函数，好强大）*//*更复杂的模式匹配，BinOp是Expr的子类，检查expr是否为BinOp，抽取它的三个组成部分(opname、left、 right)，紧接着对这些组成部分分别进行模式匹配——第一个部分匹配String+，第二个部分匹配变量e(它总是匹配)，第三个部分匹配模式Number(0)。*/def simplifyExpression(expr: Expr): Expr = expr match &#123; case BinOp(&quot;+&quot;, e, Number(0)) =&gt; e case BinOp(&quot;*&quot;, e, Number(1)) =&gt; e case BinOp(&quot;/&quot;, e, Number(1)) =&gt; e case _ =&gt; expr&#125; 代码详见：https://github.com/aloneload/FunctionTest/]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>函数式编程</tag>
        <tag>lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[函数式编程笔记（一）粮草先行]]></title>
    <url>%2F2018%2F05%2F07%2FFP1%2F</url>
    <content type="text"><![CDATA[背景 希尔伯特的第十个问题，就是不定方程(又称为丢番图方程)的可解答性。随后哥德尔不完备定理指出，对于形式化系统，存在既不能证真，也不能证伪的问题。那么哪些问题是可判定，或者说可计算的呢？Turing 和 Church 分别推出了两种不同的模型来解决可计算问题。 Church 提出 lambda 演算，并通过这一系统定义了可计算函数的符号表示，有lisp硬件实现，函数式语言，如 ML，Lisp，Haskell等则是以 lambda 演算为基础。 Turing 提出了图灵机模型，依据此模型，冯诺依曼型计算机被创造。指令式语言，如 Fortran，Pascal等都是以图灵机为基础，他们都依赖于状态序列。 后来证明，lambda演算与图灵机是等价的，能用图灵机器计算的东西lambda也可以完成。邱奇（Church）是图灵（Turing）的老师，lambda演算将所有一切看作函数，如有支持该演算的语言实现，是不是数学能证明的东西直接可以编程了呢，答案估计是这个学术用的语言还无法完全胜任实际应用，比如对于系统边界交互的IO，修改外部状态是不可避免的。于是图灵的状态机物理实现完成了反杀。 lambda简介 让我们先从数学开始说起。函数是数学中一个非常基本的概念，我们很容易就能写出一个计算平方和的函数如下: f(x,y)=xx+yy 上面这个平方和函数有个名字叫 f，有名字的好处是能方便的表示后续的计算，比如: f(3,4) = 3×3+4×4 = 25.(1) 但再想想，名字对一个函数来讲是必须的么?当然不是，下面这个映射也表示了平方和函数: (x,y)-&gt;xx+yy (2) 整体当成函数的名字，同样可以表示计算平方和过程: ((x,y)-&gt;xx+yy)(3,4) = 3×3+4×4 = 25. 我们把 (2) 称为匿名函数，它有两个参数。那么再问，单参数函数和多参数函数的区分有必要吗? 可以换个角度来看，我们把 (2) 改写成下面这个样子: x-&gt;(y-&gt; xx+yy). (3) 这个映射是什么意思呢?x被映射成了y-&gt; xx+yy ，后者是一个以 y为参数的函数。换句话说， (3)表示的是把一个数映射成函数的函数，这就是所谓的“高阶函数(” High-OrderFunction)了。注意， (3) 现在是个单参数的函数，我们可以把它先应用于参数 3，得到一个新的函数: (x-&gt;(y-&gt; xx+yy))(3) = y-&gt; 3×3+yy = y-&gt;9+yy. 再把这个函数应用于参数 4: (y-&gt;9+y*y)(4) = 9+4×4 = 25. 这样就清楚了，(3) 同样可以进行平方和的计算。用类似的方法，可以把任意多参数函数都转换成单 参数的高阶函数，这个转换又叫做柯里化(Currying)，这是以数学家 Haskell Brooks Curry 命名的。 匿名函数和柯里化，是 lambda演算为简化函数概念而采取的方法 lambda项是一种形式语言，换句话说，就是一类特殊形式的字符串罢了，没有任何内在的意义，只是个 “形式”。通常情况下，当讨论一个形式语言的时候，我们需要用另一种元语言来指称形式语言里的元 素。就如讨论自然数时，我们经常说 “对任意自然数 n”，这里的 n本身并不是自然数，用来指称自然数 罢了。我们也需要一些 “n” 来表示 lambda 项中的元素。 Alpha 替换 我们可以在命名不冲突的情况下，把表达式中绑定的标识符替换为其他标识符。 (λz.z) ≡ (λy.y) ≡ (λt.t) ≡ (λu.u) Beta 化简 在函数应用中，我们用输入的表达式代入到函数体中绑定的标识符上，这一过程称为 Beta 化简。 (λx.xy)z ≡ zy 闭包 在函数抽象中，如果函数体中存在的标识符存在于头部, 称为绑定标识符（bound variables）。在函数应用中，输入会被代换到绑定的标识符上。 不存在于头部的，称为自由标识符（free variables)。 比如下面这个表达式中，x 为 绑定变量，y为自由变量 λx.xy 此时，x作用域为有界，或者说闭包的，y是自由变量，必须从环境上下文中得到它的值 以上两条规则举例说明如下(开始的平方和例子)： λ x y.xx+yy =λ x.(λ y.xx+yy)(科里化，xy两个参数化为单参数) =λ a.(λ b.aa+bb)(α替换，就是变量名不重要，换成啥都行) =(λa.(λb.aa+bb)4)(β 化简，就是将b的值换成4) =(λa.aa+44)3 =(33+44)=25 在λ演算里面，所有的事物都是函数演算得出的，布尔值，自然数等等 T = λ x y. x（输入两个参数选其中一个） F = λ x y. y（输入两个参数选其中另一个） 以上有没有if-else的味道呢，因为λ可以作用自身，因此递归可以实现循环。 0 = λ f x. x（f作用x零次，如果f返回0++的函数是不是就实现了呢） 1 = λ f x. f x（f作用x一次） 2 = λ f x. f (f x)（f作用x 2次） 继而演算出逻辑运算and or not …还有算术运算…(于是，我们拿这些函数开始码自己的函数了) 图灵机 图灵机，又称图灵计算、图灵计算机，是由数学家阿兰·麦席森·图灵（1912～1954）提出的一种抽象计算模型，即将人们使用纸笔进行数学运算的过程进行抽象，由一个虚拟的机器替代人们进行数学运算。 所谓的图灵机就是指一个抽象的机器，它有一条无限长的纸带，纸带分成了一个一个的小方格，每个方格有不同的颜色。有一个机器头在纸带上移来移去。机器头有一组内部状态，还有一些固定的程序。在每个时刻，机器头都要从当前纸带上读入一个方格信息，然后结合自己的内部状态查找程序表，根据程序输出信息到纸带方格上，并转换自己的内部状态，然后进行移动。 这个无限长的纸带就是我们的程序。机器头里面就是指令。解释器通过纸带输入经过运算后输出到外部的纸带。 函数式编程 函数式编程是邱奇思想的在现实世界中的实现。不过不是全部的lambda演算思想都可以运用到实际中，因lambda演算在设计的时候就不是为了在各种现实世界中的限制下工作的。所以，就像面向对象的编程思想一样，函数式编程只是一系列想法，而不是一套严苛的规定。有很多支持函数式编程的程序语言，它们之间的具体设计都不完全一样。 编程语言生态系统的气候正在变化。程序员越来越多地要处理所谓的大数据，并希望利用多核计算机或计算集群来有效地处理。这意味着需要使用并行处理。 编程实战中，你是无法用Java语言以纯粹的函数式来完成一个程序的。比如，Java的I/O模型就包含了带副作用的方法(文件中读取的每一行，通常情况两次调用的结果完全不同)。不过，你还是有可能为你系统的核心组件编写接近纯粹函数式的实现。 引用透明性：“没有可感知的副作用”(不改变对调用者可见的变量、不进行I/O、不抛出异常)的这些限制都隐含着引用透明性。如果一个函数只要传递同样的参数值，总是返回同样的结果，那这个函数就是引用透明的。就好像牛顿第一定律，物体不受外力时处于平衡态（静止或匀速直线），但是现实中受到外力为零也可以是平衡态。只要修改对调用者透明就可以。换句话说，函数无论在何处、何时调用，如果使用同样的输入总能持续地得到相同的结果，就具备了函数式的特征。引用透明性是理解程序的一个重要属性。它还包含了对代价昂贵或者需长时间计算才能得到结果的变量值的优化(通过保存机制而不是重复计算)，我们通常将其称为记忆化或者缓存。 递归和迭代：纯粹的函数式编程语言通常不包含像while或者for这样的迭代构造器。为什么呢?因为这种类型诱使你修改对象。比如，while循环中，循环的条件需要更新;否则循环就一次都不会执行，要么就进入无限循环的状态。但是，很多情况下循环还是非常有用的。我们在前面的介绍中已经声明过，如果没有人能感知的话，函数式也允许进行变更，这意味着我们可以修改局部变量。遵守“引用透明性”原则的函数，其计算结构可以进行缓存。从长远看，减少共享的可变数据结构能帮助你降低维护和调试程序的代价。采用递归可以取得迭代式的结构，比如while循环。尾递归优化可避免栈溢出。 高阶函数：函数式编程的世界里，能满足下面任一要求就 可以被称为高阶函数(higher-order function):  接受至少一个函数作为参数  返回的结果是一个函数 高阶函数接受至少一个或者多个函数作为输入参数，或者返回另一个函数的函数。 科里化：是一种将具备2个参数(比如，x和y)的函数f转化为使用一个参数的函数g，并且这个函数的返回值也是一个函数，它会作为新函数的一个参数。后者的返回值和初始函数的 返回值相同，即f(x,y) =(g(x))(y)。一个函数使用所有参数仅有部分被传递时，通常我们说这个函数是部分应用的(partially applied)。一等函数是可以作为参数传递，可以作为结果返回，同时还能存储在数据结构中的函数。  科里化是一种帮助你模块化函数和重用代码的技术。  模式匹配：是一种函数式的特性，它能帮助你解包数据类型。它可以看成Java语言中switch语句的一种泛化。 闭包：“闭包”一词来源于以下两者的结合：要执行的代码块（由于自由变量被包含在代码块中，这些自由变量以及它们引用的对象没有被释放）和为自由变量提供绑定的计算环境（作用域）。一般而言，函数返回时栈上的数据都会丢失，闭包应该是在堆里。closure将函数编程与面向对象的方法结合了起来。它能在运行时从相应的域中获得变量，从而可以把该变量当成“成员变量”来访问，也因为这样，就不再需要去创建一个成员变量了。 行为参数化：就是一个方法接受多个不同的行为作为参数，并在内部使用它们，完成不同行为的能力。行为参数化可让代码更好地适应不断变化的要求，减轻未来的工作量。传递代码，就是将新行为作为参数传递给方法。在面向对象编程里，此部分可以通过继承实现行为的多态。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>函数式编程</tag>
        <tag>lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo搭建博客]]></title>
    <url>%2F2018%2F05%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[(使用hexo重构之前博客) Quick Start Create a new post 1$ hexo new "My New Post" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment 嵌入jupyter notebook 上传jupyter notebook至github,前面加入http://nbviewer.jupyter.org/,markdown文件中添加如下即可 12&lt;iframe width=&quot;1000&quot; height=&quot;1000&quot; src=&quot;http://nbviewer.jupyter.org/github/aloneload/ai/blob/master/ai_notebook.ipynb&quot; frameborder=&quot;0&quot; scrolling = &quot;no&quot;&gt;&lt;/iframe&gt;&lt;iframe width=&quot;933&quot; height=&quot;700&quot; src=&quot;https://app.powerbi.com/view?r=eyJrIjoiY2ExNmJlZDgtNGIxMC00MTU2LTkzNTItZmYzYTFiOGIwYmI0IiwidCI6ImFkNDcxZGM5LTUwODUtNGQ5Mi05ZGE2LTJiMGYyMDc4MWI0NSIsImMiOjZ9&quot; frameborder=&quot;0&quot; allowFullScreen=&quot;true&quot;&gt;&lt;/iframe&gt; more Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.]]></content>
  </entry>
  <entry>
    <title><![CDATA[计算机组成原理和操作系统]]></title>
    <url>%2F2017%2F12%2F27%2Fos%2F</url>
    <content type="text"><![CDATA[[toc] 进程管理 进程与线程 进程概念：就是一个具有独立功能的程序的一次动态执行。 进程的状态与转换： 进程的三个基本状态是就绪、执行、阻塞。就绪态到执行态的转换只需要cpu调度即可，阻塞态只能转为就绪态不能直接转为执行态。执行态如果时间片用完就转成了就绪态如果等待某事件发生就转成阻塞态。如果在这三个基本状态下进程发生挂起行为则从就绪态转为挂起或称静态就绪，从执行态转也转为静止就绪，从阻塞态转为静止阻塞。 进程控制： 进程控制就是对系统中所有进程从产生到消亡实施管理，由OS的内核实现，内核是通过调用各种原语来实现的。有进程创建原语，进程撤销原语，阻塞原语，唤醒原语等。 进程组织： 一个进程是由三部分组成的，程序、数据、进程控制块(PCB)。这三个合起来也称为进程实体。其中进程控制块是进程动态特性的集中反映，创建进程则产生pcb撤销进程就要收回pcb，pcb表项的个数是确定的，所以一个系统中的进程不是无限多的。 进程控制块很重要所以详细写点，它包含的内容很多，有 （1）进程描述信息：进程标示符（每个进程有一个唯一的号）和用户标示符（每个进程属于某个用户） （2）进程控制信息：进程当前状态，如果是阻塞的要再pcb中说明阻塞原因，进程优先级、代码执行入口地址、程序外存地址、各种计时信息(程序执行时间，页面调度情况) （3）资源管理信息：用于说明有关虚拟地址空间的现状，打开文件的列表，和使用的输入输出的信息。 （4）CPU现场保护结构：保存各种寄存器的值。 系统中pcb数目众多，他们是怎么组织起来的有链接方式和索引方式两种：链接方式就是形成就绪队列，阻塞队列等，还要对就绪队列按进程优先权排列。索引方式是建立几种状态的索引表，索引表记录pcb的地址。 进程通信 进程的互斥与同步交换的信息量较少，所以称为低级通信方式。进程之间以较高的效率传送大量数据的通信方式叫高级通信方式分为三大类： (1) 共享存储系统：就是共享内存。。其实编程没编过我对这些都理解不深刻。 (2) 消息传递系统：直接通信(send和receive通信命令直接发给接收进程)间接通信(信箱通信就是把消息放信息里让另一个进程取)。 (3) 管道通信。相当于一个队列形式的一个进程在管道尾写，另一个进程在管道头取，管道分为无名管道和有名管道。无名管道是用pipe函数创建的，只能用于子进程之间的通信，有名管道用mkfifo函数创建用于任意两个进程之间通信，对管道的操作相当于对文件的操作比如open函数打开管道close函数关闭管道等。 线程概念与多线程模型 有了线程之后，处理机调度的单位就成了线程。而资源的分配还是以进程为单位。一个进程的多个线程是公用代码数据和文件资源的，但是不同的线程有不同的寄存器和栈。线程之间的通信比进程通信方便因为有好多资源共用，线程的切换也比进程的切换简化的多。 处理机调度 调度的基本概念 调度分为作业调度，进程调度，和中级调度。作业调度就是将外存上选中的作用分配内存，创建进程等批处理中几分钟调度一次，其他系统基本不需要作业调度，进程调度就是决定就绪队列中哪个进程获得处理机。中级调度主要功能是对换，即将内存中某些就绪或阻塞的进程交换到外存对换区，主要用来进行内存管理和扩充。 调度的基本准则： CPU使用率要高，周转时间，等待时间等要小等等。周转时间等于等待时间加响应时间，平均周转时间就是各个作业的周转时间取平均值。带权周转时间等于周转时间除以响应时间，平均带权周转时间就是各个作业的带权周转时间的求平均。 调度方式： 非剥夺式和剥夺式两种。剥夺式是有抢占原则的，一般是按优先权原则，短作业优先原则和时间片原则这三种之一进行抢占的。 典型调度算法 先来先服务调度算法；短作业（短任务、短进程、短线程）优先调度算法；时间片轮转调度算法；优先级调度算法；高响应比优先调度算法(是FCFS和SJF的折中 响应比=等待时间+要求执行时间的和然后除以要求执行的时间)；多级反馈队列调度算法(多个就绪队列赋予不同的优先级优先级越高时间片越短，新进程加入后 先放第一个队列一个时间片完成不了就往下一个优先级的队列末尾放以此类推)。 进程同步 进程同步的基本概念 多个进程中发生的事件存在某种时序关系，必须协同工作，相互配合，以共同完成某一项任务。同一种进程是互斥关系，不同的进程是同步关系。 实现临界区互斥的基本方法 软件实现方法；硬件实现方法。这时候还不是信号量的那种软件实现而是程序员自己定义的，比如设置一个turn让他等于进程编号，从而使进程轮流进入临界区。还有设置一个标志位flag为0表示其他进程未进入临界区等。硬件实现方法不懂。同步机制只要实现四大准则就可以实现互斥，这四大原则就是:空闲让进、忙则等待、有限等待，让权等待。 信号量 信号量是操作系统提供的管理公有资源的手段，即PV操作。对于独享设备有驱动程序做PV操作。 p操作的过程是：s=s-1；if(s&lt;0){进入等待队列，自己阻塞进程} v操作的过程是：s=s+1；if(s&lt;0){从等待队列取一个进程；取出的进程进入就绪队列，当前进程该干嘛干嘛} pv原语不能次序错误，而且必须成对出现。信号量的定义是semaphore mutex；经典同步问题有生产者-消费者问题；读者-写者问题；哲学家进餐问题。 死锁 死锁的概念 多个进程并发执行共享资源时，由于独占资源被其他进程占用，且其他进程遇到同样的问题，于是导致出现环形等待资源的情况，所有每个进程都在等待无法执行这就是死锁。 死锁处理策略：有四种方法预防死锁、死锁避免、死锁检测、解除死锁。 死锁预防：就是破坏产生死锁的任何四个必要条件之一。死锁的四个必要条件是互斥、请求和保持、不剥夺、和环路等待。 死锁避免： 就是系统在给某进程分资源时要保证一个安全顺序，系统安全状态一般用银行家算法。银行家算法即系统试探着把资源分配给进程pi后修改可用资源的数目，还有每个进程已分配的资源数目跟每个进程还需的资源数目，然后执行安全性算法，如果此次资源分配后，系统处于安全状态才正式分配给进程资源。否则试探分配作废，让进程pi等待。注安全性算法即设置两个向量。一个work向量一个finish向量，开始时work=available，然后找到一个need小于work的进程，给该进程分配资源后使work=work+allocation ，finish=true。然后循环直到所有进程的finish状态都为true则系统处于安全状态。 死锁检测和解除： 就是检测到发生死锁之后，再采取手段解除死锁，有剥夺法，回退法和杀死进程这三种解除法。 内存管理 内存管理基础 内存管理概念 程序装入与链接；逻辑地址与物理地址空间；内存保护。内存管理的任务是记录内存的使用和空闲状态，在进程需要时为进程分配内存，用完后释放内存，已被进程使用的内存区域如何保护，如何在内存不足支持进程运行的情况下进行内外存交换。 程序的装入：指从外存装载在内存 在读入内存时需要对地址部分做调整，即重定位装入，该工作有OS专门的装载程序负责。重定位分为静态与动态重定位，静态重定位指在程序装入内存时由OS进行浮动项的定位，以后不再变化，每个可执行程序的头上有浮动项说明表，表示地址的浮动项。动态重定位是指在装入内存时不进行装配，直接将程序装入内存，定位问题由系统提供的硬件解决，需要借助硬件支持。 交换与覆盖 交换是指进程或作业在内存与外存之间的动态调度，当内存紧张时系统按某种策略将某些进程暂时移到外存，把外存某些进程换进内存占据前者的内存区域，外存分为文件区和交换区中其对换区是连续的。 覆盖是把程序划分为若干个功能相对独立的程序段。这些程序段是不会同时执行的因此可以共享同一块内存区域，若干独立的程序段叫覆盖段。当有关程序段的前一部分执行结束，把后面属于同一覆盖段的程序段调入内存，覆盖前面的程序段，相当于内存扩大了。但是增加了程序员的负担。因为程序员要向系统指明覆盖结构而且要求作业各模块之间有明确的调用结构。 连续分配管理方式 单一连续分配；分区分配。单一连续分配是指内存分为两个区域：系统区和用户区，应用程序装入到用户区可使用用户区的全部空间，这种只适合单用户单任务的OS。分区分配时把内存划分为若干个连续分区。分区分配又分为固定分区分配和动态分区分配，固定分区分配就是分区的大小是固定的，可以相等也可以不等。采用分区表记录分区的大小和使用情况。分区表的数据项有分区号，大小，起止，和状态。动态分区分配说白了就是用多少分多少。一般分区都是从地址低端开始的，动态分区按寻找空闲分区的方法的不同又分为1、首次适应法2、下次适应法3、最佳适应法。 首次适应算法是按分区的先后次序(即从低地址开始)，从头查找，找到符合要求的第一个分区，特点：较大的空闲分区被保留在内存高端，每次分配时查找时间的开销会增大。 下次适应算法是从上次分配的分区开始查找，按分区的先后次序找，特点空闲分区分布的更均匀，但较大的空闲分区不易保留。 最佳适应算法是每次找与其容量最接近的空闲分区，为了方便将按空闲区大小链接起来递增排列利用了好多外碎片。 动态分区还有动态重定位分区分配就是在动态分区的情况下，当剩余零头分区的和超过新任务要求的分区但是连续的空闲区容量却达不到新任务要求时进行紧凑的行为。就是将各个占用分区向内存一端移动，在另一端将空闲分区合并成一个空闲分区。 非连续分配管理方式 包括分页管理方式；分段管理方式；段页式管理方式。当然一个操作系统只使用其中一种管理方式。 页式管理中将逻辑地址空间分成页，物理内存划分为固定的同样大小的(硬件设计时也框的大小已经确定)页框(块)，程序可加载在不连续的块中。程序中逻辑页号和内存中物理页号的对应表叫页表，每个进程一张。系统中有一张页框使用表。系统中还有一张请求表里面存的是进程id和该进程页表地址的对应关系。逻辑地址像物理地址转换的过程：逻辑地址由两部分组成：页号和页内地址。以该页号在页表中查找对应的物理页号，然后和页内地址拼起来就是物理地址。 分段存储的段表是由段号，段长，段基址组成。由逻辑地址转换为物理地址的过程：逻辑地址由段号段内位移组成，根据段号在段表中查找段基址然后加上位移量就是在内存中的位置。 段页式存储管理的逻辑地址由段号，段内页号，页内偏移地址组成。每个进程一张段表。段表由段号，页表大小(包含几个页表)，页表首址组成。逻辑地址到物理地址的转换过程：由段号在段表中查找到对应的页表首址再与逻辑地址的页号相加，即是对应页表中该页号的对应项，将块号和页内地址拼接即求的物理地址。 分页中控制寄存器中存的是页表地址和长度，分段中控制寄存器中存的是段表使址和段表长度，段页式中控制寄存器中存的是段表始址和段表长度，根据寄存器里的值才能得到页表，段表。 虚拟内存管理 虚拟内存基本概念 借助于硬盘，一个进程部分调入内存即可运行的情况下，用到哪个程序段将外存的调入内存，对用户来说是透明的任务内存足够大到可以执行自己的程序这个思想便是虚拟内存的思想，在虚拟存储管理下，用户的逻辑地址空间可远远大于物理空间。 请求分页管理方式 即在简单页式存储管理的基础上，增加了请求调页和页面置换功能。在请求分页中的页表比简单页式存储的页表要多一些字段，包括页号、物理块号、状态位，访问字段、修改位、保护位、外存地址。状态位用来区分该页是否在内存，修改位用来表示该页在调入内存后有没有被修改，保护位表示该页是否可以修改，外存地址表示它在磁盘上现在存的位置，还有一个访问字段表示最后一次访问到现在的时间间隔用于页面置换算法的。 页面置换算法 包括最佳置换算法（OPT）；先进先出置换算法（FIFO）；最近最少使用置换算法（LRU）；时钟置换算法（CLOCK）。 最佳置换算法：选择未来最常时间里不使用的页，不能实现，因为系统不会预估未来。 先进先出：选择建立最早的页面置换，但是如果这个页经常使用，那就会被反复调入和调出，会出现随着页框增多而中断次数反而增加的现场也称为Belady异常。 最近最久未使用LRU算法：最近最久没有使用的页面，相当于访问到一个把他排队尾最后出，慢慢的队头就是最近没使用的页面淘汰队头即可。 CLOCK置换算法：是LRU和FIFO的折中。也叫二次机会算法， 页面分配策略 保证进程能运行的最小页框，固定分配：给每个进程分配固定数目的页框；可变分配是预分配给进程一定数目的页框，OS控制一定数量的空闲页框，在进程执行过程中，发生缺页时os就分配给该进程一个空闲的页框。 抖动 抖动现象和工作集。工作集指进程在执行过程中所访问页面的集合。驻留集指虚拟页式管理中给进程分配的物理块数。引入工作集目的是依据进程在过去的一段时间内访问的页面来调整常驻集大小。抖动是指内存和外存进行频繁的调入调出，产生这种情况一是因为系统进程数越来越多。每个的驻留集越来越少，因此缺页中断越来越多，这样就会使cpu使用率越来越低，二是因为不合适的调页算法。 请求分段管理方式 此时的段表比简单分段式管理的段表多了几项包括：段名，段长，段基址，存取方式，访问字段，修改字段，存在位，增补位，外存地址。存取方式指的是：执行、只读、读/写；存在位跟分页管理中的状态位是一样的，增补位指示运行过程中是否进行过动态增长。 文件管理 文件系统基础 文件概念 文件是具有文件名的一组相关元素的集合.可分为有结构文件和无结构文件,有结构的文件被看成事由一组记录组成(学过数据库都知道记录是有若干相关的数据项 组成),无结构的文件即流式文件,无格式. 文件结构 文件结构分为逻辑结构和物理结构: 文件的逻辑结构有三种: 顺序文件；索引文件；索引顺序文件。 (1)顺序文件，其记录是按某种顺序排列所形成的,比如按存入时间的先后或关键字排列.对定长记录方便直接存取,但对变长的记录,就得从第一条的长度一直加到第 n条才能知道记录的首址. (2)索引文件，记录在文件中的位置由索引表来指向，其实是按某个记录键来确定位置的,而索引表本身是定长的顺序文件.所以给定关键字后就可以在索引表中折半 查找相应的记录在哪.索引项是由记录的首址和长度构成的. (3)索引顺序文件, 将顺序文件中的记录先分为组，为顺序文件建立一张索引表，在索引表里为每组中的第一个记录建立索引项，记录在文件中的位置由索引表和顺 序来决定. 文件的物理结构也有三种:连续分配方式,链接分配方式,和索引分配方式. (1)连续分配:使得访问速度快但它要求存储空间是连续的而且必须事先知道文件的大小才能将文件存储到外存. (2)链接分配方式:将属于一个文件的多个离散盘块链接成一个链表这样所形成的一个物理文件称为链接文件.而链接分配又分为隐式链接和显示链接.隐式链接就是在该文件的离散物理块中,下一个物理块的地址由前一个物理块给出.而每个文件的第一个物理块和最后一个物理块是存储在文件目录项中的…显示链接是把用于链接文件的各个物理块指针全存放到一张链接表中,每个FAT表项存的是本物理号对应的下一个物理号是什么,一个磁盘只有一张这个表.叫做FAT文件分配表. 凡是属于某一文件的第一个盘块号，均作为文件地址被填入相应文件的FCB的物理地址字段中. (3)索引分配方式:链接分配方式需要把FAT都调入内存才能保证一个文件完整的被找到,而且一个个像下查找效率不高,索引方式为每个文件分配一个索引块,把分配给该文件的所有盘块号都记录在该索引表中,将指向该索引块的指针存入FCB中.索引分配还分为单级多级和混合索引分配方式. 至于逻辑结构和物理结构的区别. 逻辑结构是指每个记录在文件中的位置,而物理结构为逻辑结构服务,指文件在外存上存储时，分配方式要保证文件在逻辑上一致而且检索效率还有达到最高的结构. 目录管理 (1)从文件管理的角度看,文件时由文件控制块FCB和文件体组成的,文件控制块保存文件的属性信息基本包括文件名,文件结构,文件物理位置,控制信息(存取权限),管理信息(建立/修改日期等等). (2)目录是由文件说明即FCB的集合构成的.还有一种目录的组成由于每次检索文件是按名检索的,索引把整个由文件说明构成的目录调入内存是一种浪费,因此索引结点方式就诞生了,即将文件名和文件描述信息分开,将文件描述信息单独形成一个称为索引结点的数据结构,在文件目录的目录项中仅存放文件名和对应的指向索引结点的指针… (3)目录结构的形式有单级目录结构,两级目录结构和多级目录结构(也成为树形目录结构)。单级目录结构下文件不能重名查找速度也慢,两级目录是按用户建立的,即 第一级目录中存放用户名和该用户目录的指针,虽然提高了检索速度在不同用户目录中可以重名,但是不同用户文件之间的共享不方便,于是多级目录就出现了…根目录还是按用户分的,但下面有多重目录.当两个或多个用户共享文件时,不再是树形而是有向非循环图. 文件系统实现 文件系统层次结构 文件系统由三部分组成:与文件管理有关的软件,被管理的文件,实施文件管理所需的数据结构.文件系统由四层构成:最低层是基本输入输出层又叫设备驱动层,下来依次是基本文件系统层,又称物理I/O层.基本I/O管理程序层,逻辑文件系统层. (1)基本I/O层:负责启动设备I/O以及对设备发来的中断信号进行处理. (2)物理I/O层:负责处理内存和外存之间的数据块交换. (3)基本I/O管理程序层:选择文件所在设备,进行逻辑块号到物理块号的转换,对文件空闲存储空间的管理,指定I/O缓冲区等作用. (4)逻辑文件系统层:负责处理文件及记录的相关操作. 这个名字起得不好,一般物理都是最底层,结果这是是第二层不好记… 文件存储空间的管理 (1) 空闲表法和空闲链表法 空闲表法适用于连续分配方式.系统为外存上的所有空闲区建立一张空闲表,每个空闲区对应于一个空闲表项,其中包括表项序号,该空闲区的第一个盘块号,该区的空闲盘块数等信息,再将所有空闲区按其起始盘块号递增的次序排列.(对换区常用).空闲链表法.将空闲空间,以盘块为单位拉成一条链. (2) 位示图法 二进制的每一位表示磁盘中的一个盘块,当该位为1时表示已经分配,为0表示空闲.注意给出的字号和位号是从0开始还是从1开始.书上是从1开始的. (3) 成组链接法 成组链接法将一个文件的所有空闲块按每组100块分成若干组,把每组的盘块数目和该组的所有盘块号计入到前一组的第一个盘块中,第一组的盘块数目和第一组的所有盘块号计入到超级块中.这样每组的第一个盘块就连接成了一个链表,而组内的多个盘块形成了堆栈. 成组链接法的分配和回收空闲块都是所谓的头取头插,即分配从第一组开始分配,如果第一组只剩那个保存有下一组地址的块,就把该块存入超级块,下一组变成第一组.回收的时候,如果第一组满100个,那么将第一组的盘块数和盘块号写入该空闲块中,然后将盘块数等于1及栈顶块号=该空闲块号写入超级块中所以原来的第一组就变成了第二组… 磁盘组织与管理 磁盘的结构 磁盘由若干盘片组成,每个盘片有两面.都可以记录信息.每个盘面由若干磁道组成,不同半径的同心圆叫磁道.每条磁道又分为若干个扇区.每个扇区的大小相当于一个盘块.每个盘面的每一面都有一个磁头.柱面指的是不同盘面相同半径的磁道组成的圆柱… 磁盘的类型可分为固定磁头磁盘和移动磁盘磁头.磁盘的访问时间由寻道时间,旋转延迟时间和传输时间构成.(1)寻道时间:指的是把磁头移到指定磁道上所经历的时间.移动一条磁道的时间是常数.为0.2ms… (1)寻道时间等于启动磁臂的时间(常数2ms)+移动n个磁道的时间…即0.2 * n + 2 (2)旋转延迟时间为转半转所需的时间…一看都是平均数… (3)传输时间为所读/写的字节数b除以一条磁道上的字节数(除下来即表示b个字节需要转几转)再乘以一转需要的时间… 磁盘调度算法 (1) 先来先服务 没有对寻到进行优化,导致平均寻道时间可能较长. (2) 最短寻道优先 只要有新的进程要访问的磁道与当前磁头所在磁道距离较近.就会满足此进程而可能导致某些离得远的一直得不到满足. (3) 扫描算法 又称电梯调度算法,scan算法所考虑的下一个访问对象是按电梯一样的磁头移动方向下,距离正访问磁道最近的对象.容易使距离两端的进程等待将近一来一回的扫描… (4) 循环扫描算法 CSCAN算法规定了磁头必须单向移动.例如只允许磁头由内向外移动.移动到最外磁道立即返回最里面又重新开始. 磁盘的存储 可以按并行交叉存储.即连续的物理块分在不同的盘面上.一次就可以取多个,也可以在一个盘面上按顺序号存储这种效率低.容易读完1号处理完磁盘刚好旋转的把2号错过去,所以还有一种是将物理号连续的间隔起来排列. 输入输出（I/O）管理 I/O管理概述 I/O设备的分类 (1) 按传输速率分可分为低速设备(键盘鼠标等)，中速设备(激光打印机等)，高速设备(磁盘机等)。 (2) 按信息交换的单位分可分为块设备(有结构例如磁盘)和字符设备(常采用中断驱动方式) (3) 按设备的共享方式可分为独占设备(一段时间内只允许一个进程访问:例如打印机)，共享设备(一段时间内允许多个进程同时访问:例如磁盘)，虚拟设备(通过虚拟技术将独占设备变为若干台逻辑设备。) I/O管理目标 合理分配设备、提高设备与CPU，各外部设备之间的并行性，提供使用方便且独立与设备的界面。 I/O管理功能 (1) 动态的纪录各种设备的状态 (2) 设备分配与回收 (3) 实施设备驱动和中段处理的工作 I/O应用接口 (1) 设备和设备控制器的接口：设备和cpu之间不是直接通信的而是夹着一个设备控制器，设备与设备控制器是靠三根线相连的，数据信号线，控制信号线和状态信号线，数据信号线用于在设备和设备控制器之间传送数据信号，控制信号线传送由设备控制器向I/O设备发送控制信号，状态信号线用于传送设备当前状态的信号。 (2) 设备控制器：控制一个或多个I/O设备，其基本功能有接收和识别(cpu发的)命令，数据交换(与cpu或与设备数据交换)，标示和报告设备的状态(给cpu发)地址识别，数据缓冲，差错控制。 (3) 设备控制器由三部分组成：设备控制器与处理器的接口(由数据线连接DMR和控制状态寄存器，控制线，和地址线组成)，设备控制器与设备的接口(多个设备接口，每个设备接口由数据控制和状态三种信号)，I/O逻辑(当cpu启动一个设备时，将启动命令发给I/O逻辑同时通过地址线给I/O逻辑由它进行译码。。译出命令后对所选设备进行控制。所以地址线和控制线是直接跟I/O逻辑相连的。 I/O通道 I/O通道是特殊的处理机。它具有执行I/O指令的能力，并通过执行通道程序来控制I/O操作，它的指令单一主要与I/O操作相关的指令，通道没有自己的内存，它和CPU共享内存。通道又分为字节多路通道，数组选择通道，和数组多路通道。 (1) 数组选择通道:又称告诉通道，在物理上可以连接多个设备，但某一段时间内通道只能选择一个设备进行工作 (2) 数组多路通道:当某设备进行数据传送时，通道只为该设备服务，当设备在执行寻址等控制性动作时，通道挂起该设备的通道程序，去为其他设备服务。 (3) 字节多路通道:用于大量低速设备，与设备之间数据传送的基本单位是字节，为一个设备传送一个字节后，又可以为另个设备传送一个字节。数组多路通道传输的基本单位是块。而且一次只能有一个设备在传输数据。 I/O控制方式 (1) 程序I/O方式：忙等方式。 (2) 中段驱动I/O方式：当某进程要启动某个I/O设备工作时，便由cpu向相应的设备控制器发出一条I/O命令，然后立即返回继续执行原来的任务，此时，CPU和 I/O设备并行操作。以字节为单位进行I/O。 (3) DMA I/O方式：直接存储器访问方式数据传输的单位是块，数据之间在设备和内存中进行交换，仅块传输的开始和结束时才需要CPU干预。(替代了设备控制 器)。DMA控制器中有四类寄存器：命令寄存器(存cpu发的控制命令或设备的状态)，内存地址寄存器，数据寄存器(缓冲数据作用)，数据计数器(存本次要读的字节数)。 (4) I/O通道控制方式：通道是通过执行通道程序，并与设备控制器共同实现对I/O设备的控制的。通道指令格式为命令 1）操作码：规定了指令所执行的操作。 2）内存地址：标明读操作和写操作时的内存首址 3）计数：表示本条占领所要读或写数据的字节数 4）通道程序结束位P：用于表示通道程序是否结束 5）记录结束标志R。 I/O核心子系统 高速缓存与缓冲区 引入缓冲区的目的:改善CPU与外围设备之间的速度不匹配矛盾；减少对CPU的中断次数(一个位做缓冲和块做缓冲的差距)，提高CPU和I/O设备的并行性。 缓冲分为：单缓冲、双缓冲、循环缓冲、和缓冲池 单缓冲属于临界资源，而且cpu与设备无法进行并行操作。单缓冲只允许各自进程独占。双缓冲一般就有发送缓冲区和接收缓冲区。循环缓冲链成一个环形，不过 需要四个指针，比如分别指向用于读进程和写进程的已用和正在访问的单元，循环缓冲进程属于专用缓冲区。不是所有的进程都能用的。所以系统会有多个这种缓冲区。开销比较大。其实单缓冲和多缓冲也是得设置多个。因为多道程序要是设一个缓冲区岂不是没有并行性了。 缓冲池是个好想法：里面有多个进程可以共享的缓冲区。不过既然要使多个进程共享肯定结构比较复杂。有空闲缓冲区，装满输入数据的缓冲区，装满输出数据的缓冲区还有用于收容输入输出数据的缓冲区。 设备分配 设备分配中设计到4张表的数据结构，设备控制表DCT，控制器控制表COCT，通道控制表CHCT，系统设备表SDT，DCT主要包括设备标示、设备类型(块设备还是字符设备)、设备状态、等待该设备的进程、指向控制器表的指针。COCT同理，包括控制器标示符，控制器状态，与控制器连接的通道指针，等待控制器的进程队列。CHCT同上，不过它包含与该通道相连的控制器表的首地址。SDT表里包含设备控制表，还包含驱动程序入口地址等。 设备管理软件具有层次结构，细分为四级，设备中断处理程序，设备驱动程序，与设备无关的操作系统软件，用户级软件。 逻辑设备名与物理设备是有个映射表的叫逻辑设备表，基本上一个系统一个。或者一个用户一个， 数据项有逻辑设备名，物理设备名和驱动程序入口地址。 假脱机技术（SPOOLing） 假脱机技术用辅存的输入输出井替代了以前脱机技术的外围设备机的作用，使对I/O设备的操作变成对输入输出井的操作。多个进程可以同时独享设备实现了虚拟设备的功能，其实设备并没有分给某个进程，而是进程将要处理的数据放到输入输出井中，每个进程在输入输出井中分配的是一个存储区和一张I/O请求表。 计算机系统概论 计算机系统由哪两部分组成？计算机系统性能取决于什么？ 计算机系统是由“硬件”和“软件”组成。衡量一台计算机性能的优劣是根据多项技术指标综合确定的，既包括硬件的各种性能指标，又包括软件的各种功能。 1）计算机系统由硬件和软件两部分组成。 2）计算机系统性能由硬件和软件共同决定。 计算机系统5层层次结构从下到上由哪五层组成？哪些是物理机，哪些是虚拟机？ 1）微程序机器、传统机器、操作系统机器、汇编语言机器、高级语言机器 2）微程序机器和传统机器是物理机，其他是虚拟机。 在计算机系统结构中，什么是翻译？什么是解释？ 1）翻译：将一种语言编写的程序全部翻译成另一种语言，然后再执行； 2）解释：将一种语言编写的程序的一条语句翻译成另一种语言的一条或多条语句，然后执行，执行完这条语言后，再解释下一条。 什么是计算机体系结构？什么是计算机组成？以乘法指令为例说明二者区别。 1）计算机体系结构是指那些能够被程序员看到的计算机的属性。如指令集、数据类型等； 2）计算机组成是指如何实现计算机体系结构所体现出来的属性； 3）以乘法指令为例，计算机是否有乘法指令，属于体系结构的问题。乘法指令是采用专用的乘法器，还是使用加法器和移位器构成，属于计算机组成的问题。 冯诺依曼机器的主要特点？ 1）计算机由运算器、存储器、控制器、输入设备和输出设备五大部分组成； 2）指令和数据存储在存储器中，并可以按地址访问； 3）指令和数据均以二进制表示； 4）指令由操作码和地址码构成，操作码指明操作的性质，地址码表示操作数在存储器中的位置； 5）指令在存储器内按顺序存放，通常按自动的顺序取出执行； 6）机器以运算器为中心，I/O设备与存储器交换数据也要通过运算器。（因此，后来有了以存储器为中心的计算机结构） 现代计算机的组成框图。 什么是存储单元、存储字、存储字长、存储体？ 存储单元：存储一个存储字并具有特定存储地址的存储单位； 存储字：一个存储单元中存放的所有的二进制数据，按照某个地址访问某个存储单元获取的二进制数据。 存储字长：存储字中二进制数据的位数，即按照某个地址访问某个存储单元获取的二进制数据的位数； 存储体：由多个存储单元构成的存储器件。 主存储器中，什么是MAR，什么是MDR，存储器的最大容量由什么决定？ 1）MAR：存储地址寄存器，保存需要访问的存储单元地址。反映存储单元的个数。 2）MDR：存储数据寄存器，缓存读出/写入存储单元的数据。反映存储字长。 3）存储器的最大容量由MAR寄存器的位数和MDR寄存器的位数决定。 什么是机器字长，什么是存储字长长？ 机器字长：CPU一次能够处理的二进制数据的位数。 存储字长：按照某个地址访问某个存储单元获取的二进制数据的位数。 假设MAR寄存器的位数为16位，MDR寄存器的位数为16位，存储器的最大容量是多少？ 1）MAR寄存器的位数为16位，能表示的地址个数为2的16次方，为64K； 2）MDR寄存器的位数为16位，说明存储字长为16位，也即2个字节； 3）存储器的最大容量为64K * 2B = 128K Byte 系统总线 为什么要使用总线？ 在冯诺依曼结构中，各个部件之间均有单独连线，不仅线多，而且导致扩展I/O设备很不容易。即扩展一个I/O设备，需要连接很多线。 因此，引入了总线连接方式，将多个设备连接在同一组总线上，构成设备之间的公共传输通道。 总线的两大基本特征是什么？ 1）共享：多个部件连接在同一组总线上，各个部件之间都通过该总线进行数据交换。 2）分时：同一时刻，总线上只能传输一个部件发送的信息； 系统总线按照传输信息的不同，分成哪几类？是单向的，还是双向的？ 1）分成数据总线、地址总线以及控制总线。 2）数据总线：各个功能部件之间传送数据信息，双向传输； 3）地址总线：用来指明数据总线上，源数据或目的数据所在的主存单元的地址。单向：由CPU发出 4）控制总线：用来发送各种控制信号。对于控制总线中的单根线，是单向的，即只能由一个部件发向另一个部件。而一组控制总线中，有输入也有输出，因此，控制总线也可以看成是双向的。 什么是总线宽度、总线带宽、总线复用、信号线数？ 1）总线宽度：数据总线的根数，一般是8的倍数。是衡量计算机系统性能的重要指标； 2）总线带宽：即总线数据传输速率，总线上每秒能够传输的最大字节量。 3）总线复用：一条信号线上分时传送两种信号。例如数据总线和地址总线的分时复用； 4）信号线数：地址总线、数据总线和控制总线三种总线的线数之和。 假设总线的工作频率为33MHz，总线宽度为32位，则它最大的传输速率是多少？ 33 * （32/8） = 132 MB/s 简要说明单总线结构的概念及缺点？（现代计算机为什么要采用多总线结构？） 在单总线结构中，所有的部件（CPU、主存、I/O设备）都连接在一组总线上。 但所有的信息传送都要通过这组总线，同时只能有一个部件向总线上发送信息，导致总线成为系统的瓶颈。 因此，发展出来了多总线结构，其基本思想均是将速度相近的设备挂接在同一组总线上，总线之间通过总线控制器相连。 例如CPU和Cache之间、I/O设备之间等。 集中式总线判优控制有哪三种方式，哪种方式的优先级不能改变？ 1）链式查询、计数器定时查询、以及独立请求。 2）链式查询的优先级不能改变，离控制器最近的优先级最高。 什么是总线周期，分为哪几个阶段？ 1）总线周期：总线上两个部件完成一次完整且可靠的数据传输时间； 2）分为四个阶段： 申请分配阶段：申请总线 寻址阶段：发出地址及有关命令 传数阶段：进行数据交换 结束：从总线上撤除信号，让出总线 什么是总线通信控制，总线通信控制有哪几种？ 1）总线通信控制：解决通信双方如何获知传输开始和传输结束，以及如何协调配合； 2）同步通信、异步通信、半同步通信、分离式通信 什么是同步通信？其优点和缺点？ １）同步通信：总线上各个部件由统一的时钟信号控制；在总线周期中，每个时钟周期各个部件如何动作都有明确的规定。 ２）优点：速度快，各个模块间配合简单 ３）缺点：以总线上最慢的部件来设计公共时钟，影响总线效率。 什么是异步通信？异步通信分为哪几种类型？ 1）异步通信：总线上各部件没有统一的时钟标准，采用应答式通信；（主模块发出请求后，一直等到从模块反馈回来应答信号之后才开始通信） 2）不互锁、半互锁、全互锁。（需要了解各种方式的含义） 什么是波特率？什么是比特率？（需要掌握如何计算波特率、比特率） 波特率：单位时间内传送的二进制数据数据的位数，单位bps 比特率：单位时间内传送的有效的二进制位数。 异步通信时，常规需要设置的参数有哪些？ 波特率、停止位（1/2/1.5）、校验位（奇校验、偶校验、无校验） 简述半同步通信的基本原理。 半同步通信结合同步通信和异步通信。 同步通信：采用统一的时钟，规定了在一定的时钟周期干什么事情； 异步通信：如果从模块没有准备好，增加一个“等待响应”信号。 简述分离式通信的基本原理。 主模块发出地址和命令之后，放弃总线，在从模块准备数据期间，使得总线可以被其他设备所用。提高总线利用率。 但是，这种方式控制比较复杂。 奇偶校验可以纠错吗？汉明码可以纠错码？ 1）奇偶校验只能检错，不能纠错。 2）汉明码可以纠错。 存储器 存储器按存取方式，可以分成哪四类？哪些属于随机访问存储器，哪些属于串行访问存储器？ 1）可以分为随机存储器、只读存储器、顺序存储器和直接存储器； 2）随机存储器和只读存储器属于随机存储器，即存取时间与物理地址无关； 3）顺序存储器（典型的如磁带）和直接存储器（典型的如磁盘）属于串行存储器，即存取时间与物理地址有关。 衡量存储器使用哪三个指标？寄存器、缓存、主存中，哪个速度最快？哪个最便宜？ 1）速度、容量、位价格。 2）寄存器速度最快，主存最便宜。 常见的存储系统层次结构有哪两种？透明性如何？各自用来解决什么问题的？ 1）缓存-主存层次：用来缓解CPU和主存速度不匹配的问题，由硬件来完成，对所有的程序员完全透明。 2）主存-辅存层次：用来解决主存容量不够的问题，由操作系统和硬件共同完成，对应用程序设计者透明，对系统程序设计者不透明。 （现在一般存储器都即能按字访问，也能按照字节访问，因此，存储器编址时，每个字节都有一个独立的地址。） 字在存储单元中有两种存储方式，大端方式和小端方式。各是什么含义？x86采用的是哪种存储方式？ 1）大端方式：字的低位存在内存的高地址中，而字的高位存在内存的低地址中； 2）小端方式：字的低位存在内存的低地址中，而字的高位存在内存的高地址中。 3）x86CPU采用的是小端方式。 主存的三个主要技术指标 存储容量、存取速度和存储带宽 什么是存取时间？什么是存取周期？哪个大？ 1）存取时间：启动一次存储器完成本次操作（读或写）所需的时间； 2）存取周期：连续两次启动存储器所需要的最小间隔时间； 3）存取周期包含存取时间； 什么是存储器带宽？（要了解如何计算存储器带宽） 单位时间内存储器存取的信息量； 半导体存储芯片译码驱动包含哪两种方式，请简要说明。 1）线选法：所有的地址芯片通过一个译码器译码，选择一个存储单元的各位，适合于存储容量不大的芯片； 2）重合法：将地址分为两组，每组通过一个译码器译码，选择行或列，行、列交叉处就是要访问的存储位。 随机存储器包含哪两大类？哪个需要刷新？请从速度、容量、价格等方面进行简要比较。 1）静态RAM：采用锁存器原理实现； 2）动态RAM：采用电容原理实现，需要刷新。 3）相比于动态RAM，静态RAM的速度快、容量小、价格高，一般用于缓存，而动态RAM一般用于内存。 只读存储器有哪几种？ 1）掩模ROM（MROM）：出厂后内容不能被更改。 2）PROM：可编程只读存储器，可以进行一次性编程； 3）EPROM：可擦除只读ROM，用紫外线照射； 4）EEPROM：电可擦除只读ROM。 6）FLash Memory：采用EEPROM的非易失性存储器。 单片存储器芯片的容量有限，很难满足实际需要，因此必须将若干存储芯片连接在一起才能组成足够容量的存储器。 存储器的扩展通常有位扩展和字扩展，什么是字扩展，什么是位扩展？请举例简要说明 1）位扩展：增加存储器的字长，例如两个1K * 4位的存储芯片构成1个1K*8位的存储器； 2）字扩展：增加存储器的字数，例如两个1K * 8位的存储芯片构成1个2K * 8位的存储器； 通常字扩展和位扩展两种方式混合使用。 熟虑掌握存储器的扩展，包括地址空间分配、地址线的连接、数据线的连接、片选信号的产生及连接等； 假设欲检测的二进制代码为n位，为了使其具有1位的纠错能力，需添加K位检测位，组成n+k位的代码。问，应添加多少位检测位？ 应添加的检测位位数：2的k次方大于等于n+k+1。 因为要使其有1位的检测能力，必须使用k位来说明n+k位到底哪一位出现了错误，k位能表达的数量为2的k次方，而n+k位到底哪一位 出现了错误或者是全部正确，共有n+k+1种状况，因此，k的取值需要满足：2的k次方大于等于n+k+1 对于汉明码，应熟练掌握汉明码的编码方式（按照配偶或配奇的原则），以及给出汉明码，得到要传送的原始信息（包括纠错过程）。 提高访存速度的三种方式。 1）采用高速元器件； 2）采用存储层次结构：cache-主存结构； 3）调整主存结构：包括单体多字，多体并行两种方式。 简述单体多字的存储系统的工作原理，及其优点。 1）单体多字存储系统一次访存取出多个CPU字，即存储字为CPU字的n倍（假设一次访存取出n个cpu字）。 2）优点是：显著提高了存储器带宽。 多体并行系统有哪两种编址方式？请简要说明其编址方式及其优点。 1）高位交叉编址方式：存储体的编址方式为顺序存储，即一个存储体存满后，再存入下一个；存储单元地址的高位为存储体的编号。 高位交叉编址并不能提高单次访存速度，但能使多应用并行访存，提高系统的并发性。 2）低位交叉编址方式：存储体的编址方式为交叉存储。即程序连续存放在相邻的存储体之中。存储单元地址的低位为存储体的编号。 低位交叉编址能显著提高单次访存速度。 在四位低位交叉编址中，假设存取周期为T，总线传输周期为τ，为了实现流水线方式存储，应满足什么条件？如果连续读取四个字，所需要的时间是多少？ 1）T= 4τ 2）连续读取四个字，所需要的时间为T + （4-1）τ 注意：假设不是低位交叉编址，而是高位交叉编址，连续读取四个字所需要的时间仍然为4T。 需要大家掌握多体并行存储器在高位交叉编址（顺序存储）和低位交叉编址（交叉存储）的情况下，存储器带宽的计算方式。 在CPU和内存之间引入cache的原因。 1）避免cpu空等I/O访存； 2）缓解CPU和主存速度不匹配的问题。 什么是程序的局部性原理。 CPU从主存取指令或数据，在一定时间内，只是对主存局部地址区域访问。 Cache命中率、平均访问时间以及访问效率的计算。 Cache写操作有哪两种方式？ 1）写直达法：写操作既写入Cache又写入主存； 2）写回法：只把数据写入Cache而不写入主存，当Cache中数据被替换出去之后才写入主存。 将主存地址映射到Cache地址称为地址映射，常见的Cache映射方式有哪几种？ 直接映射、全相联映射、组相联映射。 直接映射的优缺点？ 优点：地址变换速度快。缺点：cache利用率不高，块冲突率高； 全相联映射的优缺点？ 优点：cache利用率高，块冲突率低。缺点：地址变换复杂，需要较多的硬件。 需要大家掌握各种映射方式之下，写出主存地址格式、cache地址格式，以及主存地址向cache地址的转换。 Cache常用的替换算法有哪些？哪个命中率最高？ 1）先进先出、近期最少使用算法和随机替换算法； 2）命中率最高的是近期最少使用算法； 磁盘的三地址结构包括哪些？ 柱面、磁头号和扇区号 输入输出系统 I/O系统的发展大致可以分为哪4个阶段？ 1）早期（分散连接、串行工作、程序查询） 2）接口模块和DMA阶段（总线连接、并行工作、中断及DMA） 3）通道阶段（通道是具有特殊功能的处理器） 4）I/O处理机阶段 I/O系统的发展实际上是逐步将CPU从繁重的I/O工作中解放出来的过程； I/O设备编址有哪两种方式？各有什么优缺点？ 1）统一编址方式：和存储器统一编址，I/O地址作为存储器地址的一部分；无须用专用的I/O指令，但占用存储器空间。 2）独立编址方式：和存储地址分开编址，需用专用的I/O指令。 I/O设备与主机的联络方式有哪几种？ I/O设备与主机间交互信息时必须了解彼此的状态。根据I/O设备工作速度的不同，可以分为3类： 1）立即响应：不管其状态（认为其时刻准备好），适用于慢速设备。 2）应答信号：通过应答信号来进行交互； 3）同步时标：采用统一的时钟信号。 I/O总线包括哪四类？ 数据线、设备选择线、状态线、命令线 I/O设备通常使用D触发器（完成触发器）和B触发器（工作触发器）来标识设备所处的状态。 D=0，B=0：暂停状态； D=0，B=1：准备状态 D=1，B=0：就绪状态 程序查询的基本工作原理。 cpu不断去查询I/O设备状态，导致CPU和I/O设备串行工作。 什么是中断？ 计算机在执行程序过程中，当出现异常清空或特殊请求时，计算机停止现行程序的运行，转去处理这些异常清空或特殊请求，处理结束后，再返回现行程序的间断处，继续执行原程序，即为中断。 中断服务程序的基本流程包括哪四部分？ 1）保护现场 2）中断服务 3）恢复现场 4）中断返回 什么是单重中断和多重中断？ 1）单重中断：不允许中断现行的中断服务程序； 2）多重中断：允许级别更高的中断源中断现行的中断服务程序，也称为中断嵌套； CPU响应中断的时机？ 当前指令执行完毕后，cpu发出中断查询信号，也就是说，中断响应一定是在每条指令执行结束之后进行的，不可能在指令执行过程中响应中断。 什么是DMA？ DMA：直接内存访问。在主存和I/O设备之间建立独立的总线连接。 在DMA方式中，由于DMA接口与CPU共享主存，可能会出现两者争用主存的冲突，为解决冲突，DMA和主存交换数据时，通常采用哪三种工作方式？ 1）停止CPU访问主存：DMA访存优先级高； 2）周期挪用（窃取）：DMA挪用存储或窃取总线使用权一个或几个主存存取周期； 3）DMA和CPU交替访问：将CPU工作周期分成两部分，一部分供DMA访存，一部分供CPU访存。 DMA工作过程包括哪三部分？ 1）预处理 2）数据传输 2）后处理 指令系统 什么是机器指令？什么是指令系统？ 1）机器指令：每一条机器语言的语句； 2）指令系统：全部机器指令的集合。 一条指令包含哪两个主要部分？请简要说明各部分作用。 1）操作码：指明指令要完成的操作； 2）地址码：指明指令要操作的数据或数据来源； 操作码长度有固定长度和可变长度两种，各自有什么优点？ 1）固定长度：便于硬件设计，指令译码时间短； 2）可变长度：压缩了操作码平均长度； 指令中地址码中的地址可以是哪些设备的地址？ 可以是主存地址、寄存器地址或I/O设备的地址； 指令中地址的个数可以有几个？ 四地址、三地址、二地址、一地址以及零地址。 假设指令中有四个地址、三个地址、两个地址以及一个地址，各自需要访存几次？ 1）四地址：访存4次； 2）三地址：访存4次； 3）两地址：访存3次； 4）一地址：访存2次； 当使用寄存器代替指令字中的地址码字段后，有哪些优点？ 1）扩大指令字的寻址范围； 2）缩短指令字长； 3）减少访存次数 数据在存储器中存储时，为什么要按照边界对齐？ 减少访存次数。 寻址方式包括哪两类？ 1）指令寻址：下一条将要执行的指令的指令地址； 2）数据寻址：确定本指令的操作数地址。 什么是形式地址？什么是有效地址？ 1）形式地址：指令的地址码字段通常都不代表操作数的真实地址，成为形式地址，记为A； 2）有效地址：操作数的真实地址，记为EA，由寻址特征和形式地址共同决定； 了解各种寻址方式的概念及根据形式地址形成有效地址的方式。 立即寻址、直接寻址、隐含寻址、间接寻址、寄存器寻址、寄存器间接寻址、基址寻址（隐式或显式）、变址寻址、相对寻址、堆栈寻址 什么是RISC？什么是CISC？ RISC：精简指令集； CISC：复杂指令集；]]></content>
      <categories>
        <category>计算机组成原理 操作系统</category>
      </categories>
      <tags>
        <tag>计算机组成原理和操作系统</tag>
      </tags>
  </entry>
</search>
